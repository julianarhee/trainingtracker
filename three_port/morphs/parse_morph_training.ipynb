{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import pymworks\n",
    "import re\n",
    "import datautils\n",
    "import copy\n",
    "import math\n",
    "import time\n",
    "\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pylab as pl\n",
    "import cPickle as pkl\n",
    "from cPickle import PicklingError\n",
    "\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some standard formatting functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "\n",
    "def natural_keys(text):\n",
    "    return [ atoi(c) for c in re.split('(\\d+)', text) ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_datafile_name(dfn):\n",
    "    fn = os.path.splitext(os.path.split(dfn)[-1])[0]\n",
    "    fparts = fn.split('_')\n",
    "\n",
    "    assert len(fparts) == 2, \"*Warning* Unknown naming fmt: %s\" % str(fparts)\n",
    "    animalid = fparts[0]\n",
    "    datestr = fparts[1]\n",
    "\n",
    "    # Make sure no exra letters are in the datestr (for parta, b, etc.)\n",
    "    if not datestr.isdigit():\n",
    "        datestr = re.split(r'\\D', datestr)[0] # cut off any letter suffix\n",
    "    if len(datestr) == 6:\n",
    "        session = '20%s' % datestr \n",
    "    elif len(datestr) == 8:\n",
    "        session = datestr \n",
    "\n",
    "    return animalid, session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File parsing functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_run_time(df):\n",
    "    state_modes = df.get_events('#state_system_mode')\n",
    "    run_bounds = None\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            running = next(d for d in state_modes if d.value==2)\n",
    "            start_time = running.time\n",
    "            strt = state_modes.index(running)\n",
    "        except StopIteration:\n",
    "            return run_bounds\n",
    "\n",
    "        try:\n",
    "            stopping = next(d for d in state_modes[strt:] if d.value != 2) \n",
    "            end_time = stopping.time\n",
    "            stp = state_modes.index(stopping)\n",
    "        except StopIteration:\n",
    "            end_time = df.get_maximum_time()\n",
    "            stp = 0\n",
    "\n",
    "        if run_bounds is None:\n",
    "            run_bounds = []\n",
    "        \n",
    "        run_bounds.append((start_time, end_time))\n",
    "\n",
    "        # Check if there are additional run chunks:\n",
    "        remaining_state_evs = state_modes[stp:]\n",
    "        additional_starts = [s for s in remaining_state_evs if s.value == 2]\n",
    "        if len(additional_starts) > 0:\n",
    "            state_modes = remaining_state_evs\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "\n",
    "    return run_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blacklisttests = [\n",
    "#     #lambda s: (('name' in s.keys()) and (s['name'] == 'pixel clock')),\n",
    "#     lambda s: (('type' in s.keys()) and (s['type'] == 'blankscreen')),\n",
    "#     ]\n",
    "\n",
    "# def to_stims(events, as_dicts=True, blacklist=None):\n",
    "#     if blacklist is None:\n",
    "#         blacklist = blacklisttests\n",
    "#     if not isinstance(blacklist, (tuple, list)):\n",
    "#         blacklist = (blacklist, )\n",
    "#     stims = []\n",
    "#     onscreen = []\n",
    "#     for e in sorted(events, key=lambda e: e.time):\n",
    "#         if e.value is None:\n",
    "#             logging.warning(\"Encountered event with value == None\")\n",
    "#             if onscreen != {}:\n",
    "#                 logging.error(\"Event.value == None with items on screen\")\n",
    "#             continue\n",
    "#         current = []\n",
    "#         if hasattr(e.value, '__getitem__'):\n",
    "#             stimulus = None\n",
    "#             pixelclock = None\n",
    "#             for stim in e.value:\n",
    "#                 if not isinstance(stim, dict) or \\\n",
    "#                         any([t(stim) for t in blacklist]):\n",
    "#                     continue\n",
    "#                 if ('name' in stim.keys()) and (stim['name'] == 'pixel clock'):\n",
    "#                     pixelclock = stim\n",
    "#                 else:\n",
    "#                     if stimulus is not None:\n",
    "#                         logging.warning(\n",
    "#                             \"Two stimuli onscreen: %s, %s\"\n",
    "#                             % (stimulus, stim))\n",
    "#                     stimulus = stim\n",
    "#             if stimulus is not None:\n",
    "#                 current.append(pymworks.events.display.Stimulus(e.time, stimulus, pixelclock))\n",
    "#         newstims, onscreen = pymworks.events.display.find_stims(onscreen, current, e.time)\n",
    "#         stims += newstims\n",
    "#     if as_dicts:\n",
    "#         return [s.to_dict() for s in stims]\n",
    "#     return stims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_trials(stim_display_events, outcome_events, outcome_key='outcome',\n",
    "              remove_unknown=True,\n",
    "              duration_multiplier=2, stim_blacklists=None):\n",
    "    \"\"\"\n",
    "    If remove_unknown, any trials where a corresponding outcome_event cannot\n",
    "    be found will be removed.\n",
    "    If duration_multiplier is not None, to_trials will check to see if the\n",
    "    outcome event occured within duration_multiplier * duration microseconds\n",
    "    of the trial start. If the outcome event occured later, the trial outcome\n",
    "    will be marked as unknown.\n",
    "    \"\"\"\n",
    "    if (len(outcome_events) == 0) or (len(stim_display_events) == 0):\n",
    "        return []\n",
    "    assert hasattr(outcome_events[0], 'name')\n",
    "\n",
    "    trials = pymworks.events.display.to_stims(stim_display_events, as_dicts=True,\n",
    "                      blacklist=stim_blacklists)\n",
    "\n",
    "    if (len(trials) == 0):\n",
    "        return []\n",
    "\n",
    "    outcomes = pymworks.events.utils.sync(outcome_events, trials,\n",
    "                          direction=1, mkey=lambda x: x['time'])\n",
    "\n",
    "    assert len(trials) == len(outcomes)\n",
    "    unknowns = []\n",
    "    if duration_multiplier is None:\n",
    "        dtest = lambda t, o: True\n",
    "    else:\n",
    "        dtest = lambda t, o: \\\n",
    "            o.time < (t['time'] + t['duration'] * duration_multiplier)\n",
    "    for i in xrange(len(trials)):\n",
    "        if (outcomes[i] is not None) and dtest(trials[i], outcomes[i]):\n",
    "            trials[i]['%s' % outcome_key] = outcomes[i].name\n",
    "            trials[i]['%s_time' % outcome_key] = outcomes[i].time\n",
    "        else:\n",
    "            if remove_unknown:\n",
    "                unknowns.append(i)\n",
    "            else:\n",
    "                trials[i]['%s' % outcome_key] = 'unknown'\n",
    "                trials[i]['%s_time' % outcome_key] = 'unknown'\n",
    "\n",
    "    # remove trials with 'unknown' outcome, in reverse\n",
    "    for u in unknowns[::-1]:\n",
    "        del trials[u]\n",
    "\n",
    "    return trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_trials(dfn, response_types=['Announce_AcquirePort1', 'Announce_AcquirePort3', 'ignore'], \\\n",
    "                 outcome_types = ['success', 'ignore', 'failure'],\\\n",
    "                 ignore_flags=[], remove_orphans=True):\n",
    "\n",
    "    print \"***** Parsing trials *****\"\n",
    "    df = pymworks.open(dfn)\n",
    "    \n",
    "    if ignore_flags is None:\n",
    "        codec = df.get_codec()\n",
    "        ignore_flags = []\n",
    "        all_flags = [f for f in codec.values() if 'Flag' in f or 'flag' in f]\n",
    "        for fl in all_flags:\n",
    "            evs = df.get_events(fl)\n",
    "            vals = list(set([v.value for v in evs]))\n",
    "            if len(vals) > 1 or len(evs) > 5:\n",
    "                ignore_flags.append(fl)\n",
    "        \n",
    "    # Get run bounds:\n",
    "    bounds = get_run_time(df)\n",
    "    if bounds is None:\n",
    "        return None, None, df\n",
    "\n",
    "    trials = []; flag_list = []; flags = {};\n",
    "    for bound in bounds:\n",
    "        \n",
    "        if (bound[1]-bound[0])/1E6 < 2.0:\n",
    "            continue\n",
    "\n",
    "        # Get display events:\n",
    "        tmp_devs = df.get_events('#stimDisplayUpdate')                     \n",
    "        tmp_devs = [i for i in tmp_devs if bound[0] <= i['time']<= bound[1]] \n",
    "\n",
    "        # Get behavior flags:\n",
    "        codec = df.get_codec()\n",
    "        all_flags = [f for f in codec.values() if 'Flag' in f or 'flag' in f]\n",
    "        flag_names = [f for f in all_flags if f not in ignore_flags]\n",
    "        tmp_flags = dict((flag, None) for flag in flag_names)\n",
    "        for flag in flag_names:\n",
    "            if flag == 'FlagNoFeedbackInCurrentTrial': continue\n",
    "            found_values = [e.value for e in df.get_events(flag) if bound[0] <= e.time <=bound[1]]\n",
    "            if (len(found_values) > 1) or (len(list(set(found_values)))) > 1:\n",
    "                print(\"More than 1 value found for flag: %s\" % flag)\n",
    "                tmp_flags[flag] = int(found_values[-1])\n",
    "            elif (len(found_values) == 1) or (len(list(set(found_values)))) == 1:\n",
    "                tmp_flags[flag] = int(found_values[0])\n",
    "            else:\n",
    "                tmp_flags.pop(flag)\n",
    "        \n",
    "        # Add current flag values to flags list:\n",
    "        flag_list.append(tmp_flags)\n",
    "        \n",
    "        # Add boundary time to flag info:\n",
    "        tmp_flags.update({'run_bounds': bound})\n",
    "\n",
    "        \n",
    "        \n",
    "        # Check for valid response types and get all response events:\n",
    "        response_types = [r for r in response_types if r in codec.values()]\n",
    "        response_evs = [e for e in df.get_events(response_types) if (bound[0] < e['time'] < bound[1]) \\\n",
    "                        and e.value!=0]\n",
    "        #responses = pymworks.events.utils.sync(response_evs, trials, direction=1, mkey=lambda x: x['time'])\n",
    "\n",
    "        # Convert to trials: match stimulus events and response events:\n",
    "        outcome_key = 'response'\n",
    "        responses = to_trials(tmp_devs, response_evs, outcome_key=outcome_key,\n",
    "                                                   duration_multiplier=2.0,\n",
    "                                                   stim_blacklists=None,\n",
    "                                                   remove_unknown=False)\n",
    "        #print response_types\n",
    "\n",
    "\n",
    "        # Get OUTCOMES:\n",
    "        #print outcome_types\n",
    "    #     outcome_evs = [e for e in df.get_events(outcome_types) if boundary[0] <= e['time']<= boundary[1] and e.value!=0] \n",
    "    #     outcomes = pymworks.events.display.to_trials(tmp_devs, outcome_evs,\n",
    "    #                                                duration_multiplier=1.0,\n",
    "    #                                                stim_blacklists=None,\n",
    "    #                                                remove_unknown=False)\n",
    "\n",
    "        # **sync outcome events to response events as master:\n",
    "        outcome_evs = [e for e in df.get_events(outcome_types) if (bound[0] < e['time'] < bound[1]) and e.value!=0]\n",
    "        outcomes = pymworks.events.utils.sync(outcome_evs, responses, direction=1, mkey=lambda x: x['response_time'])\n",
    "\n",
    "        print \"N total response events: \", len(responses)\n",
    "        print \"N total outcome events: \", len(outcomes)\n",
    "\n",
    "        assert len(responses) == len(outcomes), \"**ERROR:  N responses != N outcomes\"\n",
    "        tmp_trials = copy.copy(responses)\n",
    "        for trial_ix, (response, outcome) in enumerate(zip(responses, outcomes)):\n",
    "            if outcome is not None:\n",
    "                tmp_trials[trial_ix].update({'outcome': outcome.name, 'outcome_time': outcome.time}) #['outcome']})\n",
    "            else:\n",
    "                tmp_trials[trial_ix].update({'outcome': 'unknown'})\n",
    "\n",
    "        # Get rid of display events without known outcome within 'duration_multiplier' time\n",
    "        if remove_orphans:                                                  \n",
    "            orphans = [(i,x) for i,x in enumerate(tmp_trials) if\\\n",
    "                        x['outcome']=='unknown' or x['%s' % outcome_key]=='unknown']\n",
    "            tmp_trials = [t for t in tmp_trials if not t['outcome']=='unknown']\n",
    "            tmp_trials = [t for t in tmp_trials if not t['%s' % outcome_key]=='unknown']\n",
    "\n",
    "            print \"Found and removed %i orphan stimulus events in file %s\" % (len(orphans), df.filename)\n",
    "            print \"N valid trials: %i\" % len(tmp_trials)\n",
    "        \n",
    "        # Add current trials in chunk to trials list:\n",
    "        trials.extend(tmp_trials)\n",
    "\n",
    "    # Reformat \"name\" param for readability:\n",
    "    if len(trials) == 0:\n",
    "        return trials, flags, df\n",
    "    \n",
    "    for t in trials:\n",
    "        assert t['response_time'] < t['outcome_time'], \"**ERROR: Mismatch in response/outcome alignment\"\n",
    "        stimname = t['name']\n",
    "        t['name'] = stimname.split('.png')[0]\n",
    "    \n",
    "    # Combine all flag states:\n",
    "    for fi, flag_dict in enumerate(flag_list):\n",
    "        if fi == 0:\n",
    "            flags = copy.copy(flag_dict)\n",
    "        else:\n",
    "            for flag_name, flag_value in flag_dict.items():\n",
    "                existing_value = flags[flag_name] #.value()\n",
    "                if flag_value == existing_value:\n",
    "                    continue\n",
    "                if not isinstance(flags[flag_name], list):\n",
    "                    flags[flag_name] = list(flags[flag_name])\n",
    "                flags[flag_name].append(flag_value)\n",
    "                \n",
    "                \n",
    "    return trials, flags, df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parse manually using 'next' isntead of pymworks utils:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pos_x': 0.0, 'pos_y': 0.0, 'name': 'Blob_N2_CamRot_y0.png 1', 'filename': '/var/folders/bq/d_40rj9j1slfyy_dz1h7_7p80000gn/T/MWorks/Experiment Cache/_Users_labuser_Downloads_RatBehaviorGeneral_Behavior_3Dtransforms_2way_blobs/tmp/Blobs_TrainingRatsD1D2/Blob_N1_CamRot_y0.png', 'file_hash': '3c0f591fcbbe5741dbb1b2982cee3e696603f72d', 'duration': 799743, 'size_x': 69.87999725341797, 'size_y': 69.87999725341797, 'time': 187516752582, 'action': 'draw', 'rotation': 0.0, 'type': 'image'}\n",
      "N valid trials: 805\n"
     ]
    }
   ],
   "source": [
    "boundary = get_run_time(df)\n",
    "\n",
    "devs = [e for e in df.get_events('#stimDisplayUpdate') if boundary[0] < e['time'] < boundary[1] and e.value!=0]\n",
    "\n",
    "toofast_time = df.get_events('TooFast_time')[-1].value\n",
    "#print toofast_time\n",
    "\n",
    "\n",
    "blacklisttests = [\n",
    "    #lambda s: (('name' in s.keys()) and (s['name'] == 'pixel clock')),\n",
    "    lambda s: (('type' in s.keys()) and (s['type'] == 'blankscreen')),\n",
    "    ]\n",
    "\n",
    "stims = pymworks.events.display.to_stims(devs, as_dicts=True,\n",
    "                  blacklist=blacklisttests)\n",
    "\n",
    "# if \"aborted\" not in response types, check that all durations are > toofast time:\n",
    "stims = [t for t in stims if t['duration'] > toofast_time] #and t['duration'] >= stim_time]\n",
    "#print len(stims)\n",
    "\n",
    "print stims[0]\n",
    "\n",
    "response_types = ['Announce_AcquirePort1', 'Announce_AcquirePort3', 'ignore']\n",
    "response_evs = [e for e in df.get_events(response_types) if boundary[0] < e['time'] < boundary[1] and e.value!=0]\n",
    "response_evs = sorted(response_evs, key=lambda x: x.time)\n",
    "\n",
    "outcome_evs = [e for e in df.get_events(outcome_types) if boundary[0] < e['time'] < boundary[1] and e.value!=0]\n",
    "outcome_evs = sorted(outcome_evs, key=lambda x: x.time)\n",
    "\n",
    "orphan_stim = []\n",
    "response_ix = 0\n",
    "outcome_ix = 0\n",
    "for trial_ix, stim in enumerate(sorted(stims, key=lambda x: x['time'])):\n",
    "    try:\n",
    "        if trial_ix == len(stims)-1:\n",
    "            curr_response = next(ev for ev in response_evs[response_ix:] if ev.time > stim['time'])\n",
    "            curr_outcome = next(ev for ev in outcome_evs[outcome_ix:] if ev.time > curr_response.time)\n",
    "        else:\n",
    "            curr_response = next(ev for ev in response_evs[response_ix:] if ev.time > stim['time'] \\\n",
    "                                 and ev.time < stims[trial_ix+1]['time'])\n",
    "            curr_outcome = next(ev for ev in outcome_evs[outcome_ix:] if ev.time > curr_response.time \\\n",
    "                                 and ev.time < stims[trial_ix+1]['time'])\n",
    "            \n",
    "        stim.update({'response': curr_response.name, 'response_time': curr_response.time,\n",
    "                     'outcome': curr_outcome.name})\n",
    "        \n",
    "        response_ix = response_evs.index(curr_response) + 1\n",
    "        outcome_ix = outcome_evs.index(curr_outcome) + 1\n",
    "\n",
    "    except StopIteration:\n",
    "        orphan_stim.append(trial_ix)\n",
    "        #print trial\n",
    "\n",
    "\n",
    "valid_trials = [i for i in np.arange(0, len(stims)) if i not in orphan_stim]\n",
    "trials = [stim for stim_ix, stim in enumerate(stims) if stim_ix in valid_trials]\n",
    "print \"N valid trials: %i\" % len(trials)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[t for t, trial in enumerate(trials) if trial['outcome'] is None or trial['response'] is None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Announce_AcquirePort1', 'Announce_AcquirePort3', 'ignore']\n",
      "['success', 'ignore', 'failure']\n",
      "N total response events:  1358\n",
      "N total outcome events:  1358\n",
      "Found and removed 216 orphan stimulus events in file /n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_161130.mwk\n",
      "N valid trials: 1142\n"
     ]
    }
   ],
   "source": [
    "trials, flags = parse_trials(dfn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check that stim - response - outcome are correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'action': 'draw',\n",
       " 'duration': 799743,\n",
       " 'file_hash': '3c0f591fcbbe5741dbb1b2982cee3e696603f72d',\n",
       " 'filename': '/var/folders/bq/d_40rj9j1slfyy_dz1h7_7p80000gn/T/MWorks/Experiment Cache/_Users_labuser_Downloads_RatBehaviorGeneral_Behavior_3Dtransforms_2way_blobs/tmp/Blobs_TrainingRatsD1D2/Blob_N1_CamRot_y0.png',\n",
       " 'name': 'Blob_N2_CamRot_y0.png 1',\n",
       " 'outcome': 'failure',\n",
       " 'pos_x': 0.0,\n",
       " 'pos_y': 0.0,\n",
       " 'response': 'Announce_AcquirePort3',\n",
       " 'response_time': 187517531099,\n",
       " 'rotation': 0.0,\n",
       " 'size_x': 69.87999725341797,\n",
       " 'size_y': 69.87999725341797,\n",
       " 'time': 187516752582,\n",
       " 'type': 'image'}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blob1: 0 incorrect successes\n",
      "Blob2: 0 incorrect successes\n",
      "N ignores: 3\n"
     ]
    }
   ],
   "source": [
    "incorrect_successes = [t for t in trials if 'Blob_N1_CamRot_y' in t['name'] \\\n",
    "                         and t['outcome']=='Announce_AcquirePort3' \\\n",
    "                         and t['result'] != 'success']\n",
    "print \"Blob1: %i incorrect successes\" % len(incorrect_successes)\n",
    "\n",
    "incorrect_successes = [t for t in trials if 'Blob_N2_CamRot_y' in t['name'] \\\n",
    "                         and t['outcome']=='Announce_AcquirePort1' \\\n",
    "                         and t['result'] != 'success']\n",
    "print \"Blob2: %i incorrect successes\" % len(incorrect_successes)\n",
    "\n",
    "\n",
    "ignore_trials = [t for t in trials if t['outcome'] == 'ignore' or t['response'] == 'ignore']\n",
    "print \"N ignores: %i\" % len(ignore_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Event[code=192, name=ignore, time=187172008460, value=1],\n",
       " Event[code=192, name=ignore, time=187172189127, value=1],\n",
       " Event[code=192, name=ignore, time=187436297574, value=1],\n",
       " Event[code=192, name=ignore, time=188145252478, value=1],\n",
       " Event[code=192, name=ignore, time=188174609211, value=1],\n",
       " Event[code=192, name=ignore, time=193875666213, value=1]]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.get_events('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test trial and event parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.get_events('TooFast_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.get_events('StimulusPresentation_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codec = df.get_codec()\n",
    "ignore_flags = []\n",
    "all_flags = [f for f in codec.values() if 'Flag' in f or 'flag' in f]\n",
    "for fl in all_flags:\n",
    "    evs = df.get_events(fl)\n",
    "    vals = list(set([v.value for v in evs]))\n",
    "    if len(vals) > 1 or len(evs) > 5:\n",
    "        ignore_flags.append(fl)\n",
    "ignore_flags\n",
    "\n",
    "# If there is no \"abort\" use \"Announce_TrialEnd\" -- these should be \"aborted\" trials:\n",
    "#resp_types=['success', 'failure', 'ignore'] #, 'Announce_TrialEnd']\n",
    "resp_types=['Announce_AcquirePort1', 'Announce_AcquirePort3', 'ignore'] #, 'Announce_TrialEnd']\n",
    "\n",
    "trials, flags = parse_trials(df, resp_types=resp_types, ignore_flags=ignore_flags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "successes = [d for d in df.get_events('success') if boundary[0] < d.time < boundary[1]]\n",
    "failures = [d for d in df.get_events('failure') if boundary[0] < d.time < boundary[1]]\n",
    "ignores = [d for d in df.get_events('ignore') if boundary[0] < d.time < boundary[1]]\n",
    "ntotal = sum([len(successes), len(failures), len(ignores)])\n",
    "\n",
    "print(\"Success: %i, Failure: %i, Ignore: %i\" % (len(successes), len(failures), len(ignores)))\n",
    "print(\"TOTAL: %i\" % ntotal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "successes = [t for t in trials if t['outcome'] == 'success']\n",
    "failures = [t for t in trials if t['outcome'] == 'failure']\n",
    "ignores = [t for t in trials if t['outcome'] == 'ignore']\n",
    "\n",
    "ntotal = len(trials)\n",
    "\n",
    "print(\"Success: %i, Failure: %i, Ignore: %i\" % (len(successes), len(failures), len(ignores)))\n",
    "print(\"TOTAL: %i\" % ntotal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choice_types = ['success', 'failure', 'ignore']\n",
    "aborted = [t for t in trials if t['outcome'] not in choice_types]\n",
    "print(\"Aborted: %i\" % len(aborted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_evs = [d for d in df.get_events('ignore') if boundary[0] <= d.time <= boundary[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(d.time-1903319378052 ) / 1E6 for d in ignore_evs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Identify NoFeedback Trials:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_evs = [e for e in df.get_events('FlagNoFeedbackInCurrentTrial') if boundary[0] <= e.time <=boundary[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.get_events('FlagShowStimAfterResponse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for tix, t in enumerate(trials):\n",
    "    dur_s = t['duration']/1E6\n",
    "    if dur_s < 0.38:\n",
    "        print tix, t['outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tix, trial in enumerate(trials[0:20]):\n",
    "    ttime = (trial['time'], trial['time'] + trial['duration'])\n",
    "    nofeedback = [e.value for e in df.get_events('FlagNoFeedbackInCurrentTrial') if \\\n",
    "                  ttime[0]-1000000 <= e.time <=ttime[1] ] #and e.value==1]\n",
    "    print tix, nofeedback #len(nofeedback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fb_evs[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group trials by stimulus type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_session_meta(dfns): #, resp_types=[], remove_orphans=True, n_training_phases=5):\n",
    "    \n",
    "    sessions_info = {}\n",
    "    for dfn in sorted(dfns, key=natural_keys):\n",
    "        aid, datestr = parse_datafile_name(dfn)\n",
    "\n",
    "        if datestr in sessions_info.keys():\n",
    "            if not isinstance(sessions_info[datestr]['datasource'], list):\n",
    "                sessions_info[datestr]['datasource'] = [sessions_info[datestr]['datasource']]\n",
    "            sessions_info[datestr]['datasource'].append(dfn)\n",
    "        else:\n",
    "            sessions_info[datestr] = dict()\n",
    "            sessions_info[datestr]['datasource'] = [dfn] \n",
    "            \n",
    "        sessions_info[datestr]['animal'] = aid\n",
    "        sessions_info[datestr]['session'] = datestr\n",
    "    \n",
    "    return sessions_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Session():\n",
    "    def __init__(self, session_meta):  \n",
    "        #animalid, datestr = parse_datafile_name(dfn)\n",
    "        self.name = session_meta['animal'] #animalid\n",
    "        self.session = session_meta['session'] #datestr\n",
    "        self.source = session_meta['datasource'] #dfn\n",
    "        self.experiment = None\n",
    "        self.protocol = None\n",
    "        self.server = None # session_meta['server']\n",
    "        self.trials = None\n",
    "        self.flags = None\n",
    "        self.stimuli = None\n",
    "        self.stats = None\n",
    "        self.summary = None\n",
    "        \n",
    "    def parse_trials(self, \n",
    "                     ignore_flags=None,\n",
    "                     response_types=['Announce_AcquirePort1', 'Announce_AcquirePort3', 'ignore'],\n",
    "                     outcome_types=['success', 'failure', 'ignore']):\n",
    "                    # If there is no \"abort\" use \"Announce_TrialEnd\" ? -- these should be \"aborted\" trials?\n",
    "        \n",
    "        trials = []\n",
    "        flags = {}\n",
    "        if isinstance(self.source, list) and len(self.source) > 1:\n",
    "            tmp_flags = []\n",
    "            for dfn in self.source:\n",
    "                curr_trials, curr_flags, df = parse_trials(dfn, response_types=response_types, \n",
    "                                                       outcome_types=outcome_types,\n",
    "                                                       ignore_flags=ignore_flags)\n",
    "                if curr_trials is not None:\n",
    "                    trials.extend(curr_trials)\n",
    "                    tmp_flags.append(curr_flags)\n",
    "\n",
    "            # Combine flag values across data files:\n",
    "            if len(tmp_flags) > 0:\n",
    "                flags = dict((fkey, []) for fkey in tmp_flags[0].keys())\n",
    "                for tmp_flag in tmp_flags:\n",
    "                    for flag_key, flag_value in tmp_flag.iteritems():\n",
    "                        if flag_key not in flags.keys():\n",
    "                            flags[flag_key] = []\n",
    "                        if flag_value not in flags[flag_key]:\n",
    "                            flags[flag_key].append(flag_value)\n",
    "        else:\n",
    "            # Open data file:\n",
    "            dfn = self.source[0]\n",
    "            trials, flags, df = parse_trials(dfn, response_types=response_types, \n",
    "                                         outcome_types=outcome_types,\n",
    "                                         ignore_flags=ignore_flags)\n",
    "\n",
    "        self.trials = trials\n",
    "        self.flags = flags\n",
    "\n",
    "        # Get current session server info while df open:\n",
    "        server_address = df.get_events('#serialBridgeAddress')[-1].value\n",
    "        server_name = df.get_events('#serverName')[-1].value\n",
    "        self.server =  {'address': server_address, 'name': server_name}\n",
    "        \n",
    "        # Save experiment and protocol info:\n",
    "        # [(payload_type, event_type)]:  [(4013, 1002), (2001, 1001), (4007, 1002)] # 1002:  Datafile creation\n",
    "        experiment_load = 4013 #:  Looks like which experiment file(s) loaded (.mwk)\n",
    "        protocol_load = 2001 #:  Which protocols found and which loaded\n",
    "        sys_evs = df.get_events('#systemEvent')\n",
    "        \n",
    "        # Get experiment loaded:\n",
    "        exp_evs = [v for v in sys_evs if v.value['payload_type']==experiment_load]\n",
    "        exp_path = list(set([v.value['payload']['experiment path'] for v in exp_evs]))\n",
    "        #assert len(exp_path) == 1, \"*ERROR* More than 1 experiment loaded...\"\n",
    "        #exp_path = exp_path[0].split('/Experiment Cache/')[1]\n",
    "        self.experiment_path = exp_path\n",
    "\n",
    "        # Get protocol loaded:\n",
    "        prot_evs = [v for v in sys_evs if v.value['payload_type']==protocol_load]\n",
    "        protocol = list(set([v.value['payload']['current protocol'] for v in prot_evs]))\n",
    "        #assert len(protocol) == 1, \"*ERROR* More than 1 protocol loaded...\"\n",
    "        #protocol = protocol[0]\n",
    "        self.protocol = protocol\n",
    "        \n",
    "        \n",
    "    def get_counts_by_stimulus(self):\n",
    "        print(\"... Getting stimulus counts ...\")\n",
    "        stats = None\n",
    "        if self.trials is not None:\n",
    "            by_stim = datautils.grouping.group(self.trials, 'name')\n",
    "\n",
    "            ordered_stim = sorted(by_stim.keys(), key=lambda x: x.split('_')[-1][1:])\n",
    "            #print ordered_stim\n",
    "\n",
    "            stats = dict((stim, {}) for stim in by_stim.keys())\n",
    "            for stim in by_stim.keys():\n",
    "                stats[stim]['ntrials'] = len(by_stim[stim])\n",
    "                stats[stim]['nsuccess'] = sum([1 if trial['outcome']=='success' else 0 for trial in by_stim[stim]])\n",
    "                stats[stim]['nfailure'] = sum([1 if trial['outcome']=='failure' else 0 for trial in by_stim[stim]])\n",
    "                stats[stim]['nignore'] = sum([1 if trial['outcome']=='ignore' else 0 for trial in by_stim[stim]])\n",
    "                stats[stim]['nchoose1'] = sum([1 if trial['response']=='Announce_AcquirePort1' else 0 for trial in by_stim[stim]])\n",
    "                stats[stim]['nchoose3'] = sum([1 if trial['outcome']=='Announce_AcquirePort3' else 0 for trial in by_stim[stim]])\n",
    "\n",
    "            # Save stimulus names for easy access:\n",
    "            stimulus_names = list(set([trial['name'] for trial in self.trials]))\n",
    "            self.stimuli = stimulus_names\n",
    "        \n",
    "        self.stats = stats\n",
    "\n",
    "        \n",
    "    def get_summary(self):\n",
    "        print(\"... Getting session summary ...\")\n",
    "        # Get stats by stim, if not run:\n",
    "        if self.stats is None:\n",
    "            self.get_counts_by_stimulus()\n",
    "        \n",
    "        if self.stats is not None:\n",
    "            summary_keys = ['ntrials', 'nsuccess', 'nfailure', 'nignore']\n",
    "            summary = dict((k, 0) for k in summary_keys)\n",
    "            if len(self.stats.keys()) > 0:\n",
    "                for stat in summary.keys():\n",
    "                    summary[stat] = [val[stat] for stim, val in self.stats.items()]\n",
    "            self.summary = summary\n",
    "        \n",
    "    def plot_stats_by_transform(self, output_figdir='/tmp'):\n",
    "        print(\"... Plotting stats by transform ...\")\n",
    "        stats = self.stats\n",
    "        \n",
    "        # Check if there are morphs also:\n",
    "        morph_list = [s for s in stats.keys() if 'morph' in s]\n",
    "        if len(morph_list) > 0:\n",
    "            stimulus_list = [s for s in stats.keys() if s not in morph_list]\n",
    "        else:\n",
    "            stimulus_list = stats.keys()\n",
    "            \n",
    "        # Check stimulus name:\n",
    "        blob_names = [b for b in self.stimuli if 'Blob_' in b]\n",
    "        if 'N' in blob_names[0].split('_')[1]: # this is Blob_Nx_CamRot naming scheme:\n",
    "            blob1_name = 'Blob_N1'\n",
    "            blob2_name = 'Blob_N2'\n",
    "        else:\n",
    "            blob1_name = 'Blob_1'\n",
    "            blob2_name = 'Blob_2'\n",
    "            \n",
    "        if stats is not None:\n",
    "            values = [('%s_%s' % ('_'.join(stim.split('_')[0:2]), stim.split('_')[3]), \\\n",
    "                       stats[stim]['nsuccess']/float(stats[stim]['ntrials'])) for stim in stimulus_list]\n",
    "            print values\n",
    "\n",
    "            pl.figure()\n",
    "            if 'CamRot' in stimulus_list[0]:\n",
    "                blob1 = [(int(v[0].split('_')[-1][1:]), v[1]) for v in values if blob1_name in v[0]]\n",
    "                blob2 = [(int(v[0].split('_')[-1][1:]), v[1]) for v in values if blob2_name in v[0]]\n",
    "            else:\n",
    "                blob1 = [(int(v[0].split('_')[-1]), v[1]) for v in values if blob1_name in v[0]]\n",
    "                blob2 = [(int(v[0].split('_')[-1]), v[1]) for v in values if blob2_name in v[0]]\n",
    "                \n",
    "            pl.plot([b[0] for b in sorted(blob1, key=lambda x: x[0])], \\\n",
    "                    [b[1] for b in sorted(blob1, key=lambda x: x[0])], 'ro', label=blob1_name)\n",
    "            pl.plot([b[0] for b in sorted(blob2, key=lambda x: x[0])], \\\n",
    "                    [b[1] for b in sorted(blob2, key=lambda x: x[0])], 'bo', label=blob2_name)\n",
    "            pl.legend()\n",
    "            pl.ylim(0, 1)\n",
    "            pl.title(datestr)\n",
    "            pl.savefig(os.path.join(output_figdir, '%s_%s_bystim.png' % (self.name, self.session)))\n",
    "            pl.close()\n",
    "\n",
    "    def plot_stats_by_morph(self, output_figdir='/tmp'):\n",
    "        print(\"... Plotting stats by transform ...\")\n",
    "\n",
    "        stats = self.stats\n",
    "        stimulus_list = [s for s in stats.keys() if 'morph' in s]\n",
    "            \n",
    "        if stats is not None:\n",
    "            values = [('morph_%s' % (stim.split('morph')[1]), \\\n",
    "                       stats[stim]['nchoose1']/float(stats[stim]['ntrials'])) for stim in stimulus_list]\n",
    "\n",
    "            pl.figure()\n",
    "            pchoose1 = [(int(v[0].split('_')[-1]), v[1]) for v in values]\n",
    "            pl.plot([b[0] for b in sorted(pchoose1, key=lambda x: x[0])], \\\n",
    "                    [b[1] for b in sorted(pchoose1, key=lambda x: x[0])], 'bo')\n",
    "            pl.ylim(0, 1)\n",
    "            pl.ylabel(\"perc. choose port 1)\")\n",
    "            pl.title(datestr)\n",
    "            pl.savefig(os.path.join(output_figdir, '%s_%s_morphs.png' % (self.name, self.session)))\n",
    "            pl.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Animal():\n",
    "    def __init__(self, animalid='RAT', experiment='EXPERIMENT', output_datadir='/tmp'):\n",
    "        self.animalid = animalid\n",
    "        self.experient = experiment\n",
    "        self.outdir = output_datadir\n",
    "        self.sessions = {}\n",
    "        \n",
    "    def get_sessions(self, dfns):\n",
    "        session_info = get_session_meta(dfns)\n",
    "        return session_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_session(session_meta, \n",
    "                    output_figdir='/tmp',\n",
    "                    response_types=['Announce_AcquirePort1', 'Announce_AcquirePort3', 'ignore'],\n",
    "                    outcome_types=['success', 'ignore', 'failure'],\n",
    "                    ignore_flags=None):\n",
    "    \n",
    "    S = Session(session_meta)\n",
    "    print session_meta\n",
    "    S.parse_trials(response_types=['Announce_AcquirePort1', 'Announce_AcquirePort3', 'ignore'], \\\n",
    "                 outcome_types = ['success', 'ignore', 'failure'])\n",
    "\n",
    "    S.get_summary() #S.get_counts_by_stimulus()\n",
    "\n",
    "    if S.summary is None or S.summary['ntrials'] == 0:\n",
    "        return None\n",
    "    \n",
    "    S.plot_stats_by_transform(output_figdir=output_figdir)\n",
    "\n",
    "    if any('morph' in i for i in S.stimuli):\n",
    "        S.plot_stats_by_morph(output_figdir=output_figdir)\n",
    "        \n",
    "    # Save tmp file:\n",
    "    tmp_file_dir = os.path.join(output_figdir, 'tmp_files')\n",
    "    if not os.path.exists(tmp_file_dir): os.makedirs(tmp_file_dir)\n",
    "    with open(os.path.join(tmp_file_dir, 'proc_%s_%s.pkl' % (S.name, S.session)), 'wb') as f:\n",
    "        pkl.dump(S, f, protocol=pkl.HIGHEST_PROTOCOL)\n",
    "        \n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sessions_mp(new_sessions, session_info,\n",
    "                         output_figdir='/tmp',\n",
    "                         nprocesses=1,\n",
    "                         ignore_flags=None,\n",
    "                         response_types=['Announce_AcquirePort1', 'Announce_AcquirePort3', 'ignore'],\n",
    "                         outcome_types = ['success', 'ignore', 'failure']):\n",
    "    \n",
    "    print \"SAVING FIGURES TO:\", output_figdir\n",
    "    \n",
    "    def parser(curr_sessions, session_info, ignore_flags, response_types, outcome_types, output_figdir, out_q):\n",
    "        parsed_sessions = {}\n",
    "        for datestr in curr_sessions:\n",
    "            session_meta = session_info[datestr]\n",
    "            S = process_session(session_meta, \n",
    "                                output_figdir=output_figdir,\n",
    "                                ignore_flags=ignore_flags,\n",
    "                                response_types=response_types, \n",
    "                                outcome_types=outcome_types)\n",
    "            parsed_sessions[datestr] = S\n",
    "        out_q.put(parsed_sessions)\n",
    "    \n",
    "    # Get a chunksize of sessions to process and queue for outputs:\n",
    "    out_q = mp.Queue()\n",
    "    chunksize = int(math.ceil(len(new_sessions) / float(nprocesses)))\n",
    "    procs = []\n",
    "    for i in range(nprocesses):\n",
    "        p = mp.Process(target=parser,\n",
    "                      args=(new_sessions[chunksize * i:chunksize * (i + 1)],\n",
    "                           session_info, \n",
    "                           ignore_flags,\n",
    "                           response_types,\n",
    "                           outcome_types,\n",
    "                           output_figdir,\n",
    "                           out_q))\n",
    "        procs.append(p)\n",
    "        p.start()\n",
    "        \n",
    "    # Collect all results into single dict:\n",
    "    processed_dict = {}\n",
    "    for i in range(nprocesses):\n",
    "        processed_dict.update(out_q.get())\n",
    "    \n",
    "    # Wait for all worker processes to finish:\n",
    "#     for p in procs:\n",
    "#         print \"Finished:\", p\n",
    "#         p.join()\n",
    "    TIMEOUT = 60\n",
    "    start = time.time()\n",
    "    while time.time() - start <= TIMEOUT:\n",
    "        if any([p.is_alive() for p in procs]):\n",
    "            time.sleep(.1)\n",
    "        else:\n",
    "            break # all processes complete, break\n",
    "    else:\n",
    "        # kill processes if time out\n",
    "        print(\"timed out... killing all processes.\")\n",
    "        for p in procs:\n",
    "            p.terminate()\n",
    "            p.join()\n",
    "            \n",
    "        \n",
    "    return processed_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse .mwk data files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Set sources and output dirs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set path params:\n",
    "root = '/n/coxfs01/behavior-data'\n",
    "experiment = 'threeport_morphs'\n",
    "cohort = 'AG'\n",
    "\n",
    "# Set experiment parsing vars and params:\n",
    "response_types = ['Announce_AcquirePort1', 'Announce_AcquirePort3', 'ignore']\n",
    "outcome_types = outcome_types = ['success', 'ignore', 'failure']\n",
    "ignore_flags = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving parsed datafiles to: /n/coxfs01/behavior-data/threeport_morphs/AG/processed/data\n",
      "Saving figures to: /n/coxfs01/behavior-data/threeport_morphs/AG/processed/figures\n"
     ]
    }
   ],
   "source": [
    "# Create output dirs:\n",
    "output_dir = os.path.join(root, experiment, cohort, 'processed')\n",
    "output_figdir = os.path.join(output_dir, 'figures')\n",
    "output_datadir = os.path.join(output_dir, 'data')\n",
    "if not os.path.exists(output_figdir): os.makedirs(output_figdir)\n",
    "if not os.path.exists(output_datadir): os.makedirs(output_datadir)\n",
    "\n",
    "\n",
    "print(\"Saving parsed datafiles to: %s\" % output_datadir)\n",
    "print(\"Saving figures to: %s\" % output_figdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Get list of all datafiles for each animal in cohort\n",
    "Datafile format:  ANIMALID_YYMMDD.mwk (convert datestr to YYYYMMDD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "Found 12 animals in cohort AG.\n",
      "-- first session: 20150202, last session: 20170202 --\n",
      "N sessions per animal:\n",
      "AG1: 205 sessions\n",
      "AG2: 196 sessions\n",
      "AG3: 29 sessions\n",
      "AG4: 156 sessions\n",
      "AG5: 172 sessions\n",
      "AG6: 173 sessions\n",
      "AG7: 189 sessions\n",
      "AG8: 190 sessions\n",
      "AG9: 132 sessions\n",
      "AG10: 155 sessions\n",
      "AG11: 155 sessions\n",
      "AG12: 42 sessions\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Get list of a.. raw data files:\n",
    "raw_fns = glob.glob(os.path.join(root, experiment, cohort, 'raw', '*.mwk'))\n",
    "\n",
    "sessions = {}\n",
    "for fn in raw_fns:\n",
    "    animalid, datestr = parse_datafile_name(fn)\n",
    "    if animalid not in sessions.keys():\n",
    "        sessions[animalid] = []\n",
    "    sessions[animalid].append(int(datestr))\n",
    "    \n",
    "    \n",
    "animalids = sorted(sessions.keys(), key=natural_keys)\n",
    "nsessions = [len(sessions[animal]) for animal in sorted(animalids, key=natural_keys)]\n",
    "all_sessions = sorted([int(item) for sublist in sessions.values() for item in sublist])\n",
    "\n",
    "print('----------------------------------------------')\n",
    "print(\"Found %i animals in cohort %s.\" % (len(animalids), cohort))\n",
    "print(\"-- first session: %i, last session: %i --\" % (all_sessions[0], all_sessions[-1]))\n",
    "print(\"N sessions per animal:\")\n",
    "for animalid, session_count in zip(animalids, nsessions):\n",
    "    print(\"%s: %i sessions\" % (animalid, session_count))\n",
    "print('----------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.  Process new datafiles for each animal in cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AG2:  \n",
    "# up thru 20150313 - Blob_1_RotDept_0\n",
    "# starting 20150314 -- Blob_1_CamRot_y0\n",
    "# morphs start 20160623\n",
    "\n",
    "animalid = 'AG3'\n",
    "\n",
    "session_list = sessions[animalid]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get current animal session info:\n",
    "animal = Animal(animalid=animalid, experiment=experiment, output_datadir=output_datadir)\n",
    "curr_dfns = [dfn for dfn in raw_fns if animalid == os.path.splitext(os.path.split(dfn)[-1])[0].split('_')[0] or animalid == os.path.splitext(os.path.split(dfn)[-1])[0].split('_')[1]]\n",
    "session_info = animal.get_sessions(curr_dfns)\n",
    "\n",
    "# Create animal datafile:\n",
    "animal_datafile = os.path.join(output_datadir, '%s.pkl' % animalid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'20150203': {'animal': 'AG3',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_150203.mwk'],\n",
       "  'session': '20150203'},\n",
       " '20150204': {'animal': 'AG3',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_150204.mwk'],\n",
       "  'session': '20150204'},\n",
       " '20160127': {'animal': 'AG3',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160127.mwk'],\n",
       "  'session': '20160127'},\n",
       " '20160713': {'animal': 'AG3',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160713.mwk'],\n",
       "  'session': '20160713'},\n",
       " '20160714': {'animal': 'AG3',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160714.mwk'],\n",
       "  'session': '20160714'},\n",
       " '20160715': {'animal': 'AG3',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160715.mwk'],\n",
       "  'session': '20160715'},\n",
       " '20160716': {'animal': 'AG3',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160716.mwk'],\n",
       "  'session': '20160716'},\n",
       " '20160718': {'animal': 'AG3',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160718.mwk'],\n",
       "  'session': '20160718'},\n",
       " '20160719': {'animal': 'AG3',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160719.mwk'],\n",
       "  'session': '20160719'},\n",
       " '20160720': {'animal': 'AG3',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160720.mwk'],\n",
       "  'session': '20160720'},\n",
       " '20160722': {'animal': 'AG3',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160722.mwk'],\n",
       "  'session': '20160722'},\n",
       " '20160723': {'animal': 'AG3',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160723.mwk'],\n",
       "  'session': '20160723'},\n",
       " '20160725': {'animal': 'AG3',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160725.mwk'],\n",
       "  'session': '20160725'},\n",
       " '20160726': {'animal': 'AG3',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160726.mwk'],\n",
       "  'session': '20160726'},\n",
       " '20160727': {'animal': 'AG3',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160727.mwk'],\n",
       "  'session': '20160727'},\n",
       " '20160802': {'animal': 'AG3',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160802.mwk'],\n",
       "  'session': '20160802'},\n",
       " '20160803': {'animal': 'AG3',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160803.mwk'],\n",
       "  'session': '20160803'},\n",
       " '20160804': {'animal': 'AG3',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160804.mwk'],\n",
       "  'session': '20160804'},\n",
       " '20160805': {'animal': 'AG3',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160805.mwk'],\n",
       "  'session': '20160805'},\n",
       " '20160809': {'animal': 'AG3',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160809.mwk'],\n",
       "  'session': '20160809'},\n",
       " '20160810': {'animal': 'AG3',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160810.mwk'],\n",
       "  'session': '20160810'},\n",
       " '20160811': {'animal': 'AG3',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160811.mwk'],\n",
       "  'session': '20160811'},\n",
       " '20160812': {'animal': 'AG3',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160812.mwk'],\n",
       "  'session': '20160812'},\n",
       " '20160813': {'animal': 'AG3',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160813.mwk'],\n",
       "  'session': '20160813'},\n",
       " '20160814': {'animal': 'AG3',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160814.mwk'],\n",
       "  'session': '20160814'},\n",
       " '20160815': {'animal': 'AG3',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160815.mwk'],\n",
       "  'session': '20160815'},\n",
       " '20160816': {'animal': 'AG3',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160816.mwk'],\n",
       "  'session': '20160816'},\n",
       " '20160817': {'animal': 'AG3',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160817.mwk'],\n",
       "  'session': '20160817'},\n",
       " '20160818': {'animal': 'AG3',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160818.mwk'],\n",
       "  'session': '20160818'}}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[s for s, sd in session_info.items() if sd['animal'] != animalid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AG3]: Found 0 processed sessions.\n",
      "[AG3]: There are 29 out of 29 found session datafiles to process.\n"
     ]
    }
   ],
   "source": [
    "# Check if processed file exists -- load or create new.\n",
    "create_new = False\n",
    "if os.path.exists(animal_datafile):\n",
    "    try:\n",
    "        with open(animal_datafile, 'rb') as f:\n",
    "            animal = pkl.load(f)   \n",
    "    except EOFError:\n",
    "        create_new = True\n",
    "        \n",
    "if create_new:\n",
    "    animal = Animal(animalid=animalid, experiment=experiment, output_datadir=output_datadir)\n",
    "\n",
    "\n",
    "# Process new datafiles / sessions:\n",
    "old_sessions = [sesh for sesh, sobject in animal.sessions.items() if sobject is not None]\n",
    "print(\"[%s]: Found %i processed sessions.\" % (animalid, len(old_sessions)))\n",
    "all_sessions = session_info.keys()\n",
    "new_sessions = [s for s in all_sessions if s not in old_sessions]\n",
    "\n",
    "print(\"[%s]: There are %i out of %i found session datafiles to process.\" % (animal.animalid, len(new_sessions), len(all_sessions)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING FIGURES TO: /n/coxfs01/behavior-data/threeport_morphs/AG/processed/figures\n",
      "{'session': '20160127', 'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160127.mwk'], 'animal': 'AG3'}\n",
      "***** Parsing trials *****\n",
      "{'session': '20160725', 'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160725.mwk'], 'animal': 'AG3'}\n",
      "***** Parsing trials *****\n",
      "{'session': '20160722', 'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160722.mwk'], 'animal': 'AG3'}\n",
      "***** Parsing trials *****\n",
      "{'session': '20160804', 'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160804.mwk'], 'animal': 'AG3'}\n",
      "***** Parsing trials *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Event before 9954886 was missing required code, time, and/or value\n",
      "WARNING:root:Event before 16309805 was missing required code, time, and/or value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N total response events:  969\n",
      "N total outcome events:  969\n",
      "Found and removed 79 orphan stimulus events in file /n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160127.mwk\n",
      "N valid trials: 890\n",
      "... Getting session summary ...\n",
      "... Getting stimulus counts ...\n",
      "... Plotting stats by transform ...\n",
      "[('Blob_N2_y45', 1.0), ('Blob_N1_y60', 0.7777777777777778), ('Blob_N1_y-15', 0.85), ('Blob_N2_y-30', 0.8709677419354839), ('Blob_N1_y45', 0.8823529411764706), ('Blob_N1_y-15', 0.6666666666666666), ('Blob_N2_y-15', 0.7058823529411765), ('Blob_N2_y30', 0.72), ('Blob_N2_y0', 0.9545454545454546), ('Blob_N1_y0', 0.75), ('Blob_N2_y-30', 0.6470588235294118), ('Blob_N1_y45', 0.5714285714285714), ('Blob_N2_y30', 0.8333333333333334), ('Blob_N2_y60', 0.6818181818181818), ('Blob_N2_y0', 0.6111111111111112), ('Blob_N2_y-30', 0.875), ('Blob_N2_y-15', 0.8846153846153846), ('Blob_N2_y45', 0.6190476190476191), ('Blob_N1_y0', 0.21739130434782608), ('Blob_N1_y30', 0.8333333333333334), ('Blob_N1_y0', 0.6842105263157895), ('Blob_N2_y-15', 0.7727272727272727), ('Blob_N1_y60', 0.7), ('Blob_N1_y-45', 0.7692307692307693), ('Blob_N2_y-45', 0.8571428571428571), ('Blob_N2_y45', 0.6923076923076923), ('Blob_N1_y-30', 0.8214285714285714), ('Blob_N1_y-45', 0.9230769230769231), ('Blob_N2_y30', 0.85), ('Blob_N2_y-45', 0.5238095238095238), ('Blob_N1_y-30', 0.6875), ('Blob_N1_y45', 0.84), ('Blob_N1_y30', 0.32142857142857145), ('Blob_N2_y60', 0.8823529411764706), ('Blob_N2_y-45', 0.6428571428571429), ('Blob_N1_y-30', 0.5454545454545454), ('Blob_N1_y-15', 0.35294117647058826), ('Blob_N2_y60', 0.7391304347826086), ('Blob_N1_y30', 0.6111111111111112), ('Blob_N1_y60', 0.9583333333333334), ('Blob_N1_y-45', 0.5), ('Blob_N2_y0', 0.9130434782608695)]\n",
      "{'session': '20150204', 'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_150204.mwk'], 'animal': 'AG3'}\n",
      "***** Parsing trials *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Event before 7239361 was missing required code, time, and/or value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N total response events:  928\n",
      "N total outcome events:  928\n",
      "Found and removed 89 orphan stimulus events in file /n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160804.mwk\n",
      "N valid trials: 839\n",
      "... Getting session summary ...\n",
      "... Getting stimulus counts ...\n",
      "... Plotting stats by transform ...\n",
      "[('Blob_N2_y60', 0.4), ('Blob_N2_y45', 0.3333333333333333), ('Blob_N1_y45', 0.5333333333333333), ('Blob_N1_y60', 0.4666666666666667), ('Blob_N2_y15', 0.3), ('Blob_N1_y-30', 0.6), ('Blob_N1_y-15', 0.6666666666666666), ('Blob_N1_y0', 0.5786516853932584), ('Blob_N2_y30', 0.5517241379310345), ('Blob_N1_y-45', 0.45161290322580644), ('Blob_N2_y-45', 0.5862068965517241), ('Blob_N2_y0', 0.430939226519337), ('Blob_N1_y30', 0.6), ('Blob_N2_y-60', 0.5), ('Blob_N1_y15', 0.7666666666666667), ('Blob_N2_y-15', 0.43333333333333335), ('Blob_N1_y-60', 0.4666666666666667), ('Blob_N2_y-30', 0.45161290322580644)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Event before 52865296 was missing required code, time, and/or value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'session': '20160803', 'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160803.mwk'], 'animal': 'AG3'}\n",
      "***** Parsing trials *****\n",
      "N total response events:  637\n",
      "N total outcome events:  637\n",
      "Found and removed 327 orphan stimulus events in file /n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_150204.mwk\n",
      "N valid trials: 310\n",
      "... Getting session summary ...\n",
      "... Getting stimulus counts ...\n",
      "... Plotting stats by transform ...\n",
      "[('Blob_2_0', 0.49390243902439024), ('Blob_1_0', 0.5205479452054794)]\n",
      "{'session': '20150203', 'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_150203.mwk'], 'animal': 'AG3'}\n",
      "***** Parsing trials *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Event before 1306160 was missing required code, time, and/or value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "More than 1 value found for flag: FlagAutomaticBiasSuppression\n",
      "More than 1 value found for flag: FlagStaircaseHorizSeparation\n",
      "More than 1 value found for flag: FlagStaircaseProbFreeRew\n",
      "More than 1 value found for flag: FlagEnrichSomeStaircases\n",
      "More than 1 value found for flag: FlagForceCueStimSoundOff\n",
      "More than 1 value found for flag: FlagShowOnlyTrainedAxes\n",
      "More than 1 value found for flag: FlagDiscardHalfOfTheTrials\n",
      "More than 1 value found for flag: FlagDiscardTrialWithCurrentDeptRot\n",
      "More than 1 value found for flag: FlagSampUniformDistr\n",
      "More than 1 value found for flag: FlagStaircaseSize\n",
      "More than 1 value found for flag: FlagStaircasePosHR\n",
      "More than 1 value found for flag: FlagStaircasePosHL\n",
      "More than 1 value found for flag: FlagStaircasePosVU\n",
      "More than 1 value found for flag: FlagStaircasePosVD\n",
      "More than 1 value found for flag: FlagStaircaseRotCW\n",
      "More than 1 value found for flag: FlagStaircaseRotACW\n",
      "More than 1 value found for flag: FlagStaircaseDeptRotRight\n",
      "More than 1 value found for flag: FlagStaircaseDeptRotLeft\n",
      "More than 1 value found for flag: Flag_MatchCurrStairTrial\n",
      "More than 1 value found for flag: FlagPlayOutcomeSound\n",
      "More than 1 value found for flag: FlagLongPunishment\n",
      "More than 1 value found for flag: FlagCorrectionTrials\n",
      "More than 1 value found for flag: FlagAlwaysReward\n",
      "More than 1 value found for flag: FlagAlwaysEnforceMaxSeqLeng\n",
      "More than 1 value found for flag: FlagShowVisualStimuli\n",
      "More than 1 value found for flag: FlagCueStimSound\n",
      "More than 1 value found for flag: FlagShowStimRight\n",
      "More than 1 value found for flag: FlagShowStimLeft\n",
      "More than 1 value found for flag: FlagShowStimAfterResponse\n",
      "N total response events:  118\n",
      "N total outcome events:  118\n",
      "Found and removed 9 orphan stimulus events in file /n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_150203.mwk\n",
      "N valid trials: 109\n",
      "... Getting session summary ...\n",
      "... Getting stimulus counts ...\n",
      "... Plotting stats by transform ...\n",
      "[('Blob_2_0', 0.16363636363636364), ('Blob_1_0', 0.2037037037037037)]\n",
      "{'session': '20160716', 'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160716.mwk'], 'animal': 'AG3'}\n",
      "***** Parsing trials *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Event before 13583158 was missing required code, time, and/or value\n",
      "WARNING:root:Event before 88605364 was missing required code, time, and/or value\n",
      "WARNING:root:Event before 11829165 was missing required code, time, and/or value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N total response events:  792\n",
      "N total outcome events:  792\n",
      "Found and removed 109 orphan stimulus events in file /n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160803.mwk\n",
      "N valid trials: 683\n",
      "... Getting session summary ...\n",
      "... Getting stimulus counts ...\n",
      "... Plotting stats by transform ...\n",
      "[('Blob_N2_y60', 0.25), ('Blob_N2_y45', 0.25), ('Blob_N1_y45', 0.68), ('Blob_N1_y60', 0.7083333333333334), ('Blob_N2_y15', 0.375), ('Blob_N1_y-30', 0.5833333333333334), ('Blob_N1_y-15', 0.64), ('Blob_N1_y0', 0.6870748299319728), ('Blob_N2_y30', 0.2916666666666667), ('Blob_N1_y-45', 0.64), ('Blob_N2_y-45', 0.3333333333333333), ('Blob_N2_y0', 0.3108108108108108), ('Blob_N1_y30', 0.875), ('Blob_N2_y-60', 0.375), ('Blob_N1_y15', 0.52), ('Blob_N2_y-15', 0.375), ('Blob_N1_y-60', 0.875), ('Blob_N2_y-30', 0.4583333333333333)]\n",
      "{'session': '20160802', 'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160802.mwk'], 'animal': 'AG3'}\n",
      "***** Parsing trials *****\n",
      "N total response events:  645\n",
      "N total outcome events:  645\n",
      "Found and removed 96 orphan stimulus events in file /n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160716.mwk\n",
      "N valid trials: 549\n",
      "... Getting session summary ...\n",
      "... Getting stimulus counts ...\n",
      "... Plotting stats by transform ...\n",
      "[('Blob_N2_y60', 0.45), ('Blob_N2_y45', 0.4), ('Blob_N1_y45', 0.7368421052631579), ('Blob_N1_y60', 0.75), ('Blob_N2_y15', 0.25), ('Blob_N1_y-30', 0.7894736842105263), ('Blob_N1_y-15', 0.5263157894736842), ('Blob_N1_y0', 0.6470588235294118), ('Blob_N2_y30', 0.47368421052631576), ('Blob_N1_y-45', 0.5263157894736842), ('Blob_N2_y-45', 0.3157894736842105), ('Blob_N2_y0', 0.3474576271186441), ('Blob_N1_y30', 0.85), ('Blob_N2_y-60', 0.3), ('Blob_N1_y15', 0.8), ('Blob_N2_y-15', 0.2631578947368421), ('Blob_N1_y-60', 0.65), ('Blob_N2_y-30', 0.10526315789473684)]\n",
      "{'session': '20160818', 'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160818.mwk'], 'animal': 'AG3'}\n",
      "***** Parsing trials *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Event before 11387388 was missing required code, time, and/or value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N total response events:  903\n",
      "N total outcome events:  903\n",
      "Found and removed 111 orphan stimulus events in file /n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160722.mwk\n",
      "N valid trials: 792\n",
      "... Getting session summary ...\n",
      "... Getting stimulus counts ...\n",
      "... Plotting stats by transform ...\n",
      "[('Blob_N2_y60', 0.3103448275862069), ('Blob_N2_y45', 0.21428571428571427), ('Blob_N1_y45', 0.6785714285714286), ('Blob_N1_y60', 0.7142857142857143), ('Blob_N2_y15', 0.25), ('Blob_N1_y-30', 0.8214285714285714), ('Blob_N1_y-15', 0.4827586206896552), ('Blob_N1_y0', 0.7289156626506024), ('Blob_N2_y30', 0.3103448275862069), ('Blob_N1_y-45', 0.6785714285714286), ('Blob_N2_y-45', 0.21428571428571427), ('Blob_N2_y0', 0.3488372093023256), ('Blob_N1_y30', 0.75), ('Blob_N2_y-60', 0.25), ('Blob_N1_y15', 0.75), ('Blob_N2_y-15', 0.2413793103448276), ('Blob_N1_y-60', 0.5517241379310345), ('Blob_N2_y-30', 0.41379310344827586)]\n",
      "{'session': '20160811', 'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160811.mwk'], 'animal': 'AG3'}\n",
      "***** Parsing trials *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Event before 13624233 was missing required code, time, and/or value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N total response events:  672\n",
      "N total outcome events:  672\n",
      "Found and removed 105 orphan stimulus events in file /n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160802.mwk\n",
      "N valid trials: 567\n",
      "... Getting session summary ...\n",
      "... Getting stimulus counts ...\n",
      "... Plotting stats by transform ...\n",
      "[('Blob_N2_y60', 0.19047619047619047), ('Blob_N2_y45', 0.3), ('Blob_N1_y45', 0.7142857142857143), ('Blob_N1_y60', 0.55), ('Blob_N2_y15', 0.3), ('Blob_N1_y-30', 0.9), ('Blob_N1_y-15', 0.6190476190476191), ('Blob_N1_y0', 0.6639344262295082), ('Blob_N2_y30', 0.35), ('Blob_N1_y-45', 0.75), ('Blob_N2_y-45', 0.35), ('Blob_N2_y0', 0.43333333333333335), ('Blob_N1_y30', 0.7), ('Blob_N2_y-60', 0.3), ('Blob_N1_y15', 0.7727272727272727), ('Blob_N2_y-15', 0.35), ('Blob_N1_y-60', 0.8), ('Blob_N2_y-30', 0.3)]\n",
      "{'session': '20160715', 'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160715.mwk'], 'animal': 'AG3'}\n",
      "***** Parsing trials *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Event before 12099228 was missing required code, time, and/or value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N total response events:  591\n",
      "N total outcome events:  591\n",
      "Found and removed 53 orphan stimulus events in file /n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160811.mwk\n",
      "N valid trials: 538\n",
      "... Getting session summary ...\n",
      "... Getting stimulus counts ...\n",
      "... Plotting stats by transform ...\n",
      "[('Blob_N2_y60', 0.3157894736842105), ('Blob_N2_y45', 0.3), ('Blob_N1_y45', 0.6), ('Blob_N1_y60', 0.5789473684210527), ('Blob_N2_y15', 0.2631578947368421), ('Blob_N1_y-30', 0.7894736842105263), ('Blob_N1_y-15', 0.7368421052631579), ('Blob_N1_y0', 0.7017543859649122), ('Blob_N2_y30', 0.5263157894736842), ('Blob_N1_y-45', 0.6190476190476191), ('Blob_N2_y-45', 0.2), ('Blob_N2_y0', 0.2782608695652174), ('Blob_N1_y30', 0.8947368421052632), ('Blob_N2_y-60', 0.21052631578947367), ('Blob_N1_y15', 0.631578947368421), ('Blob_N2_y-15', 0.42105263157894735), ('Blob_N1_y-60', 0.7894736842105263), ('Blob_N2_y-30', 0.3157894736842105)]\n",
      "{'session': '20160719', 'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160719.mwk'], 'animal': 'AG3'}\n",
      "***** Parsing trials *****\n",
      "N total response events:  1079\n",
      "N total outcome events:  1079\n",
      "Found and removed 140 orphan stimulus events in file /n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160725.mwk\n",
      "N valid trials: 939\n",
      "... Getting session summary ...\n",
      "... Getting stimulus counts ...\n",
      "... Plotting stats by transform ...\n",
      "[('Blob_N2_y60', 0.45454545454545453), ('Blob_N2_y45', 0.2857142857142857), ('Blob_N1_y45', 0.7272727272727273), ('Blob_N1_y60', 0.7878787878787878), ('Blob_N2_y15', 0.2727272727272727), ('Blob_N1_y-30', 0.6470588235294118), ('Blob_N1_y-15', 0.7878787878787878), ('Blob_N1_y0', 0.6732673267326733), ('Blob_N2_y30', 0.1388888888888889), ('Blob_N1_y-45', 0.7352941176470589), ('Blob_N2_y-45', 0.21212121212121213), ('Blob_N2_y0', 0.39), ('Blob_N1_y30', 0.6666666666666666), ('Blob_N2_y-60', 0.36363636363636365), ('Blob_N1_y15', 0.8823529411764706), ('Blob_N2_y-15', 0.12121212121212122), ('Blob_N1_y-60', 0.696969696969697), ('Blob_N2_y-30', 0.3235294117647059)]\n",
      "{'session': '20160810', 'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160810.mwk'], 'animal': 'AG3'}\n",
      "***** Parsing trials *****\n",
      "N total response events:  661\n",
      "N total outcome events:  661\n",
      "Found and removed 95 orphan stimulus events in file /n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160715.mwk\n",
      "N valid trials: 566\n",
      "... Getting session summary ...\n",
      "... Getting stimulus counts ...\n",
      "... Plotting stats by transform ...\n",
      "[('Blob_N2_y60', 0.45), ('Blob_N2_y45', 0.5), ('Blob_N1_y45', 0.7), ('Blob_N1_y60', 0.75), ('Blob_N2_y15', 0.25), ('Blob_N1_y-30', 0.7), ('Blob_N1_y-15', 0.7), ('Blob_N1_y0', 0.7107438016528925), ('Blob_N2_y30', 0.23809523809523808), ('Blob_N1_y-45', 0.7142857142857143), ('Blob_N2_y-45', 0.15), ('Blob_N2_y0', 0.3442622950819672), ('Blob_N1_y30', 0.6190476190476191), ('Blob_N2_y-60', 0.35), ('Blob_N1_y15', 0.8), ('Blob_N2_y-15', 0.3), ('Blob_N1_y-60', 0.8), ('Blob_N2_y-30', 0.25)]\n",
      "{'session': '20160714', 'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160714.mwk'], 'animal': 'AG3'}\n",
      "***** Parsing trials *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Event before 9662705 was missing required code, time, and/or value\n",
      "WARNING:root:Event before 14616710 was missing required code, time, and/or value\n",
      "WARNING:root:Event before 9482757 was missing required code, time, and/or value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N total response events:  598\n",
      "N total outcome events:  598\n",
      "Found and removed 61 orphan stimulus events in file /n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160810.mwk\n",
      "N valid trials: 537\n",
      "... Getting session summary ...\n",
      "... Getting stimulus counts ...\n",
      "... Plotting stats by transform ...\n",
      "[('Blob_N2_y60', 0.47368421052631576), ('Blob_N2_y45', 0.2631578947368421), ('Blob_N1_y45', 0.7368421052631579), ('Blob_N1_y60', 0.7368421052631579), ('Blob_N2_y15', 0.3684210526315789), ('Blob_N1_y-30', 0.7368421052631579), ('Blob_N1_y-15', 0.631578947368421), ('Blob_N1_y0', 0.6752136752136753), ('Blob_N2_y30', 0.42105263157894735), ('Blob_N1_y-45', 0.7368421052631579), ('Blob_N2_y-45', 0.3157894736842105), ('Blob_N2_y0', 0.3739130434782609), ('Blob_N1_y30', 0.7894736842105263), ('Blob_N2_y-60', 0.3684210526315789), ('Blob_N1_y15', 0.5263157894736842), ('Blob_N2_y-15', 0.3), ('Blob_N1_y-60', 0.8421052631578947), ('Blob_N2_y-30', 0.2631578947368421)]\n",
      "{'session': '20160723', 'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160723.mwk'], 'animal': 'AG3'}\n",
      "***** Parsing trials *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Event before 109489609 was missing required code, time, and/or value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N total response events:  531\n",
      "N total outcome events:  531\n",
      "Found and removed 86 orphan stimulus events in file /n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160714.mwk\n",
      "N valid trials: 445\n",
      "... Getting session summary ...\n",
      "... Getting stimulus counts ...\n",
      "... Plotting stats by transform ...\n",
      "[('Blob_N2_y60', 0.1875), ('Blob_N2_y45', 0.3125), ('Blob_N1_y45', 0.8666666666666667), ('Blob_N1_y60', 0.75), ('Blob_N2_y15', 0.26666666666666666), ('Blob_N1_y-30', 0.7333333333333333), ('Blob_N1_y-15', 0.875), ('Blob_N1_y0', 0.6842105263157895), ('Blob_N2_y30', 0.3125), ('Blob_N1_y-45', 0.7647058823529411), ('Blob_N2_y-45', 0.35294117647058826), ('Blob_N2_y0', 0.3402061855670103), ('Blob_N1_y30', 0.6666666666666666), ('Blob_N2_y-60', 0.25), ('Blob_N1_y15', 0.7333333333333333), ('Blob_N2_y-15', 0.375), ('Blob_N1_y-60', 0.375), ('Blob_N2_y-30', 0.3125)]\n",
      "N total response events:  803\n",
      "N total outcome events:  803\n",
      "Found and removed 122 orphan stimulus events in file /n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160719.mwk\n",
      "N valid trials: 681\n",
      "... Getting session summary ...\n",
      "... Getting stimulus counts ...\n",
      "... Plotting stats by transform ...\n",
      "[('Blob_N2_y60', 0.32), ('Blob_N2_y45', 0.25), ('Blob_N1_y45', 0.5833333333333334), ('Blob_N1_y60', 0.5833333333333334), ('Blob_N2_y15', 0.36), ('Blob_N1_y-30', 0.8333333333333334), ('Blob_N1_y-15', 0.7307692307692307), ('Blob_N1_y0', 0.7448275862068966), ('Blob_N2_y30', 0.20833333333333334), ('Blob_N1_y-45', 0.6), ('Blob_N2_y-45', 0.4166666666666667), ('Blob_N2_y0', 0.4305555555555556), ('Blob_N1_y30', 0.8), ('Blob_N2_y-60', 0.28), ('Blob_N1_y15', 0.7916666666666666), ('Blob_N2_y-15', 0.2916666666666667), ('Blob_N1_y-60', 0.75), ('Blob_N2_y-30', 0.36)]\n",
      "{'session': '20160718', 'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160718.mwk'], 'animal': 'AG3'}\n",
      "***** Parsing trials *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Event before 15633338 was missing required code, time, and/or value\n",
      "WARNING:root:Event before 88675175 was missing required code, time, and/or value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N total response events:  844\n",
      "N total outcome events:  844\n",
      "Found and removed 130 orphan stimulus events in file /n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160718.mwk\n",
      "N valid trials: 714\n",
      "... Getting session summary ...\n",
      "... Getting stimulus counts ...\n",
      "... Plotting stats by transform ...\n",
      "[('Blob_N2_y60', 0.3076923076923077), ('Blob_N2_y45', 0.28), ('Blob_N1_y45', 0.64), ('Blob_N1_y60', 0.76), ('Blob_N2_y15', 0.37037037037037035), ('Blob_N1_y-30', 0.68), ('Blob_N1_y-15', 0.76), ('Blob_N1_y0', 0.7051282051282052), ('Blob_N2_y30', 0.19230769230769232), ('Blob_N1_y-45', 0.5416666666666666), ('Blob_N2_y-45', 0.28), ('Blob_N2_y0', 0.33557046979865773), ('Blob_N1_y30', 0.52), ('Blob_N2_y-60', 0.4), ('Blob_N1_y15', 0.6923076923076923), ('Blob_N2_y-15', 0.3103448275862069), ('Blob_N1_y-60', 0.7692307692307693), ('Blob_N2_y-30', 0.32)]\n",
      "{'session': '20160812', 'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160812.mwk'], 'animal': 'AG3'}\n",
      "***** Parsing trials *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Event before 20846888 was missing required code, time, and/or value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N total response events:  1347\n",
      "N total outcome events:  1347\n",
      "Found and removed 135 orphan stimulus events in file /n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160818.mwk\n",
      "N valid trials: 1212\n",
      "... Getting session summary ...\n",
      "... Getting stimulus counts ...\n",
      "... Plotting stats by transform ...\n",
      "[('Blob_N2_y-15', 0.24), ('Blob_N1_y0', 0.6209150326797386), ('Blob_N2_y-30', 0.38461538461538464), ('Blob_N2_y0', 0.4900662251655629), ('Blob_N1_y-60', 0.52), ('Blob_N2_y15', 0.44), ('Blob_N2_y30', 0.6), ('Blob_N1_y30', 0.36), ('Blob_N1_y15', 0.52), ('Blob_N1_y-30', 0.32), ('Blob_N1_y-15', 0.6153846153846154), ('Blob_N2_y-45', 0.5185185185185185), ('Blob_N2_y-60', 0.52), ('Blob_N2_y45', 0.4), ('Blob_N1_y-45', 0.56), ('Blob_N1_y45', 0.6), ('Blob_N1_y60', 0.44), ('Blob_N2_y60', 0.36)]\n",
      "... Plotting stats by transform ...\n",
      "{'session': '20160726', 'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160726.mwk'], 'animal': 'AG3'}\n",
      "***** Parsing trials *****\n",
      "N total response events:  1169\n",
      "N total outcome events:  1169\n",
      "Found and removed 142 orphan stimulus events in file /n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160812.mwk\n",
      "N valid trials: 1027\n",
      "... Getting session summary ...\n",
      "... Getting stimulus counts ...\n",
      "... Plotting stats by transform ...\n",
      "[('Blob_N2_y60', 0.2972972972972973), ('Blob_N2_y45', 0.5135135135135135), ('Blob_N1_y45', 0.5555555555555556), ('Blob_N1_y60', 0.5675675675675675), ('Blob_N2_y15', 0.5), ('Blob_N1_y-30', 0.7567567567567568), ('Blob_N1_y-15', 0.6756756756756757), ('Blob_N1_y0', 0.6409090909090909), ('Blob_N2_y30', 0.40540540540540543), ('Blob_N1_y-45', 0.5833333333333334), ('Blob_N2_y-45', 0.5405405405405406), ('Blob_N2_y0', 0.4818181818181818), ('Blob_N1_y30', 0.6216216216216216), ('Blob_N2_y-60', 0.4166666666666667), ('Blob_N1_y15', 0.5405405405405406), ('Blob_N2_y-15', 0.42105263157894735), ('Blob_N1_y-60', 0.6111111111111112), ('Blob_N2_y-30', 0.4444444444444444)]\n",
      "{'session': '20160809', 'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160809.mwk'], 'animal': 'AG3'}\n",
      "***** Parsing trials *****\n",
      "N total response events:  972\n",
      "N total outcome events:  972\n",
      "Found and removed 93 orphan stimulus events in file /n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160723.mwk\n",
      "N valid trials: 879\n",
      "... Getting session summary ...\n",
      "... Getting stimulus counts ...\n",
      "... Plotting stats by transform ...\n",
      "[('Blob_N2_y60', 0.375), ('Blob_N2_y45', 0.3225806451612903), ('Blob_N1_y45', 0.8387096774193549), ('Blob_N1_y60', 0.7096774193548387), ('Blob_N2_y15', 0.1875), ('Blob_N1_y-30', 0.71875), ('Blob_N1_y-15', 0.65625), ('Blob_N1_y0', 0.7315789473684211), ('Blob_N2_y30', 0.25806451612903225), ('Blob_N1_y-45', 0.7741935483870968), ('Blob_N2_y-45', 0.41935483870967744), ('Blob_N2_y0', 0.3404255319148936), ('Blob_N1_y30', 0.7741935483870968), ('Blob_N2_y-60', 0.5161290322580645), ('Blob_N1_y15', 0.7096774193548387), ('Blob_N2_y-15', 0.1935483870967742), ('Blob_N1_y-60', 0.6774193548387096), ('Blob_N2_y-30', 0.40625)]\n",
      "{'session': '20160720', 'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160720.mwk'], 'animal': 'AG3'}\n",
      "***** Parsing trials *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Event before 14494258 was missing required code, time, and/or value\n",
      "WARNING:root:Event before 15774678 was missing required code, time, and/or value\n",
      "WARNING:root:Event before 80561203 was missing required code, time, and/or value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N total response events:  855\n",
      "N total outcome events:  855\n",
      "Found and removed 108 orphan stimulus events in file /n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160809.mwk\n",
      "N valid trials: 747\n",
      "... Getting session summary ...\n",
      "... Getting stimulus counts ...\n",
      "... Plotting stats by transform ...\n",
      "[('Blob_N2_y60', 0.38461538461538464), ('Blob_N2_y45', 0.35714285714285715), ('Blob_N1_y45', 0.6538461538461539), ('Blob_N1_y60', 0.5555555555555556), ('Blob_N2_y15', 0.3333333333333333), ('Blob_N1_y-30', 0.6666666666666666), ('Blob_N1_y-15', 0.5185185185185185), ('Blob_N1_y0', 0.6770186335403726), ('Blob_N2_y30', 0.2692307692307692), ('Blob_N1_y-45', 0.5), ('Blob_N2_y-45', 0.6666666666666666), ('Blob_N2_y0', 0.4716981132075472), ('Blob_N1_y30', 0.5925925925925926), ('Blob_N2_y-60', 0.4230769230769231), ('Blob_N1_y15', 0.5925925925925926), ('Blob_N2_y-15', 0.38461538461538464), ('Blob_N1_y-60', 0.7777777777777778), ('Blob_N2_y-30', 0.5925925925925926)]\n",
      "{'session': '20160713', 'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160713.mwk'], 'animal': 'AG3'}\n",
      "***** Parsing trials *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Event before 5168691 was missing required code, time, and/or value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N total response events:  863\n",
      "N total outcome events:  863\n",
      "Found and removed 103 orphan stimulus events in file /n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160720.mwk\n",
      "N valid trials: 760\n",
      "... Getting session summary ...\n",
      "... Getting stimulus counts ...\n",
      "... Plotting stats by transform ...\n",
      "[('Blob_N2_y60', 0.48148148148148145), ('Blob_N2_y45', 0.4444444444444444), ('Blob_N1_y45', 0.6666666666666666), ('Blob_N1_y60', 0.7857142857142857), ('Blob_N2_y15', 0.3333333333333333), ('Blob_N1_y-30', 0.6296296296296297), ('Blob_N1_y-15', 0.6296296296296297), ('Blob_N1_y0', 0.656441717791411), ('Blob_N2_y30', 0.4444444444444444), ('Blob_N1_y-45', 0.8214285714285714), ('Blob_N2_y-45', 0.2222222222222222), ('Blob_N2_y0', 0.3395061728395062), ('Blob_N1_y30', 0.5555555555555556), ('Blob_N2_y-60', 0.25925925925925924), ('Blob_N1_y15', 0.7857142857142857), ('Blob_N2_y-15', 0.4444444444444444), ('Blob_N1_y-60', 0.6666666666666666), ('Blob_N2_y-30', 0.37037037037037035)]\n",
      "{'session': '20160813', 'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160813.mwk'], 'animal': 'AG3'}\n",
      "***** Parsing trials *****\n",
      "N total response events:  266\n",
      "N total outcome events:  266\n",
      "Found and removed 43 orphan stimulus events in file /n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160713.mwk\n",
      "N valid trials: 223\n",
      "... Getting session summary ...\n",
      "... Getting stimulus counts ...\n",
      "... Plotting stats by transform ...\n",
      "[('Blob_N2_y60', 0.375), ('Blob_N2_y45', 0.75), ('Blob_N1_y45', 0.875), ('Blob_N1_y60', 0.5714285714285714), ('Blob_N2_y15', 0.25), ('Blob_N1_y-30', 1.0), ('Blob_N1_y-15', 0.375), ('Blob_N1_y0', 0.7142857142857143), ('Blob_N2_y30', 0.25), ('Blob_N1_y-45', 0.4444444444444444), ('Blob_N2_y-45', 0.42857142857142855), ('Blob_N2_y0', 0.41304347826086957), ('Blob_N1_y30', 0.625), ('Blob_N2_y-60', 0.5), ('Blob_N1_y15', 0.75), ('Blob_N2_y-15', 0.625), ('Blob_N1_y-60', 0.375), ('Blob_N2_y-30', 0.375)]\n",
      "{'session': '20160805', 'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160805.mwk'], 'animal': 'AG3'}\n",
      "***** Parsing trials *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Event before 18683148 was missing required code, time, and/or value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N total response events:  1\n",
      "N total outcome events:  1\n",
      "Found and removed 0 orphan stimulus events in file /n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160726.mwk\n",
      "N valid trials: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Event before 46743060 was missing required code, time, and/or value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N total response events:  1199\n",
      "N total outcome events:  1199\n",
      "Found and removed 177 orphan stimulus events in file /n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160726.mwk\n",
      "N valid trials: 1022\n",
      "... Getting session summary ...\n",
      "... Getting stimulus counts ...\n",
      "... Plotting stats by transform ...\n",
      "[('Blob_N2_y-15', 0.2857142857142857), ('Blob_N1_y0', 0.6796875), ('Blob_N2_y-30', 0.3181818181818182), ('Blob_N2_y0', 0.3515625), ('Blob_N1_y-60', 0.7142857142857143), ('Blob_N2_y15', 0.47619047619047616), ('Blob_N2_y30', 0.42857142857142855), ('Blob_N1_y30', 0.7142857142857143), ('Blob_N1_y15', 0.7272727272727273), ('Blob_N1_y-30', 0.8571428571428571), ('Blob_N1_y-15', 0.6818181818181818), ('Blob_N2_y-45', 0.47619047619047616), ('Blob_N2_y-60', 0.23809523809523808), ('Blob_N2_y45', 0.5714285714285714), ('Blob_N1_y-45', 0.7142857142857143), ('Blob_N1_y45', 0.7272727272727273), ('Blob_N1_y60', 0.6666666666666666), ('Blob_N2_y60', 0.2857142857142857)]\n",
      "N total response events:  1074\n",
      "N total outcome events:  1074\n",
      "... Plotting stats by transform ...\n",
      "Found and removed 76 orphan stimulus events in file /n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160805.mwk\n",
      "N valid trials: 998\n",
      "... Getting session summary ...\n",
      "... Getting stimulus counts ...\n",
      "... Plotting stats by transform ...\n",
      "[('Blob_N2_y60', 0.4722222222222222), ('Blob_N2_y45', 0.42857142857142855), ('Blob_N1_y45', 0.5675675675675675), ('Blob_N1_y60', 0.5833333333333334), ('Blob_N2_y15', 0.4857142857142857), ('Blob_N1_y-30', 0.5714285714285714), ('Blob_N1_y-15', 0.6388888888888888), ('Blob_N1_y0', 0.5953488372093023), ('Blob_N2_y30', 0.5428571428571428), ('Blob_N1_y-45', 0.5277777777777778), ('Blob_N2_y-45', 0.6285714285714286), ('Blob_N2_y0', 0.4549763033175355), ('Blob_N1_y30', 0.7428571428571429), ('Blob_N2_y-60', 0.32432432432432434), ('Blob_N1_y15', 0.5277777777777778), ('Blob_N2_y-15', 0.3055555555555556), ('Blob_N1_y-60', 0.6666666666666666), ('Blob_N2_y-30', 0.4722222222222222)]\n",
      "{'session': '20160727', 'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160727.mwk'], 'animal': 'AG3'}\n",
      "***** Parsing trials *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Event before 17620365 was missing required code, time, and/or value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N total response events:  1491\n",
      "N total outcome events:  1491\n",
      "Found and removed 170 orphan stimulus events in file /n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160813.mwk\n",
      "N valid trials: 1321\n",
      "... Getting session summary ...\n",
      "... Getting stimulus counts ...\n",
      "... Plotting stats by transform ...\n",
      "[('Blob_N2_y-15', 0.5), ('Blob_N1_y0', 0.5767634854771784), ('Blob_N2_y-30', 0.525), ('Blob_N1_y-60', 0.525), ('Blob_N2_y15', 0.325), ('Blob_N2_y30', 0.5), ('Blob_N1_y30', 0.5), ('Blob_N1_y15', 0.675), ('Blob_N1_y-30', 0.675), ('Blob_N1_y-15', 0.55), ('Blob_N2_y-45', 0.425), ('Blob_N2_y-60', 0.525), ('Blob_N2_y45', 0.525), ('Blob_N1_y-45', 0.725), ('Blob_N1_y45', 0.75), ('Blob_N1_y60', 0.5), ('Blob_N2_y60', 0.475), ('Blob_N2_y0', 0.5166666666666667)]\n",
      "... Plotting stats by transform ...\n",
      "{'session': '20160814', 'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160814.mwk'], 'animal': 'AG3'}\n",
      "***** Parsing trials *****\n",
      "N total response events:  1214\n",
      "N total outcome events:  1214\n",
      "Found and removed 159 orphan stimulus events in file /n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160727.mwk\n",
      "N valid trials: 1055\n",
      "... Getting session summary ...\n",
      "... Getting stimulus counts ...\n",
      "... Plotting stats by transform ...\n",
      "[('Blob_N2_y-15', 0.2727272727272727), ('Blob_N1_y0', 0.7862595419847328), ('Blob_N2_y-30', 0.13636363636363635), ('Blob_N2_y0', 0.3484848484848485), ('Blob_N1_y-60', 0.7142857142857143), ('Blob_N2_y15', 0.36363636363636365), ('Blob_N2_y30', 0.4090909090909091), ('Blob_N1_y30', 0.5454545454545454), ('Blob_N1_y15', 0.6818181818181818), ('Blob_N1_y-30', 0.5909090909090909), ('Blob_N1_y-15', 0.6363636363636364), ('Blob_N2_y-45', 0.36363636363636365), ('Blob_N2_y-60', 0.2727272727272727), ('Blob_N2_y45', 0.3181818181818182), ('Blob_N1_y-45', 0.8636363636363636), ('Blob_N1_y45', 0.6521739130434783), ('Blob_N1_y60', 0.6363636363636364), ('Blob_N2_y60', 0.2727272727272727)]\n",
      "... Plotting stats by transform ...\n",
      "{'session': '20160816', 'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160816.mwk'], 'animal': 'AG3'}\n",
      "***** Parsing trials *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Event before 105816522 was missing required code, time, and/or value\n",
      "WARNING:root:Event before 88637372 was missing required code, time, and/or value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N total response events:  808\n",
      "N total outcome events:  808\n",
      "Found and removed 74 orphan stimulus events in file /n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160816.mwk\n",
      "N valid trials: 734\n",
      "... Getting session summary ...\n",
      "... Getting stimulus counts ...\n",
      "... Plotting stats by transform ...\n",
      "[('Blob_N2_y-15', 0.5217391304347826), ('Blob_N1_y0', 0.696969696969697), ('Blob_N1_y-45', 0.8636363636363636), ('Blob_N2_y-30', 0.45454545454545453), ('Blob_N2_y0', 0.41911764705882354), ('Blob_N1_y-60', 0.8636363636363636), ('Blob_N2_y15', 0.4090909090909091), ('Blob_N2_y30', 0.4090909090909091), ('Blob_N1_y30', 0.6363636363636364), ('Blob_N1_y15', 0.6363636363636364), ('Blob_N1_y-30', 0.7272727272727273), ('Blob_N1_y-15', 0.8181818181818182), ('Blob_N2_y-45', 0.34782608695652173), ('Blob_N2_y-60', 0.22727272727272727), ('Blob_N2_y45', 0.2727272727272727), ('Blob_N1_y45', 0.6818181818181818), ('Blob_N1_y60', 0.7391304347826086), ('Blob_N2_y60', 0.4090909090909091)]\n",
      "... Plotting stats by transform ...\n",
      "N total response events:  1408\n",
      "N total outcome events:  1408\n",
      "Found and removed 215 orphan stimulus events in file /n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160814.mwk\n",
      "N valid trials: 1193\n",
      "... Getting session summary ...\n",
      "... Getting stimulus counts ...\n",
      "... Plotting stats by transform ...\n",
      "[('Blob_N2_y-15', 0.5945945945945946), ('Blob_N1_y0', 0.5694444444444444), ('Blob_N1_y-45', 0.5555555555555556), ('Blob_N2_y-30', 0.4722222222222222), ('Blob_N2_y0', 0.5391705069124424), ('Blob_N1_y-60', 0.4166666666666667), ('Blob_N2_y15', 0.6944444444444444), ('Blob_N2_y30', 0.5833333333333334), ('Blob_N1_y30', 0.4444444444444444), ('Blob_N1_y15', 0.5277777777777778), ('Blob_N1_y-30', 0.3611111111111111), ('Blob_N1_y-15', 0.6111111111111112), ('Blob_N2_y-45', 0.4722222222222222), ('Blob_N2_y-60', 0.5945945945945946), ('Blob_N2_y45', 0.6666666666666666), ('Blob_N1_y45', 0.5), ('Blob_N1_y60', 0.5135135135135135), ('Blob_N2_y60', 0.3888888888888889)]\n",
      "... Plotting stats by transform ...\n",
      "{'session': '20160815', 'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160815.mwk'], 'animal': 'AG3'}\n",
      "***** Parsing trials *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Event before 127406496 was missing required code, time, and/or value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N total response events:  1545\n",
      "N total outcome events:  1545\n",
      "Found and removed 282 orphan stimulus events in file /n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160815.mwk\n",
      "N valid trials: 1263\n",
      "... Getting session summary ...\n",
      "... Getting stimulus counts ...\n",
      "... Plotting stats by transform ...\n",
      "[('Blob_N2_y-15', 0.41025641025641024), ('Blob_N1_y0', 0.6826086956521739), ('Blob_N1_y-45', 0.6578947368421053), ('Blob_N2_y-30', 0.47368421052631576), ('Blob_N2_y0', 0.48695652173913045), ('Blob_N1_y-60', 0.7692307692307693), ('Blob_N2_y15', 0.5641025641025641), ('Blob_N2_y30', 0.3684210526315789), ('Blob_N1_y30', 0.631578947368421), ('Blob_N1_y15', 0.5), ('Blob_N1_y-30', 0.5789473684210527), ('Blob_N1_y-15', 0.6578947368421053), ('Blob_N2_y-45', 0.34210526315789475), ('Blob_N2_y-60', 0.34210526315789475), ('Blob_N2_y45', 0.2894736842105263), ('Blob_N1_y45', 0.7105263157894737), ('Blob_N1_y60', 0.6153846153846154), ('Blob_N2_y60', 0.47368421052631576)]\n",
      "... Plotting stats by transform ...\n",
      "{'session': '20160817', 'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160817.mwk'], 'animal': 'AG3'}\n",
      "***** Parsing trials *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Event before 85690085 was missing required code, time, and/or value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N total response events:  979\n",
      "N total outcome events:  979\n",
      "Found and removed 127 orphan stimulus events in file /n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG3_160817.mwk\n",
      "N valid trials: 852\n",
      "... Getting session summary ...\n",
      "... Getting stimulus counts ...\n",
      "... Plotting stats by transform ...\n",
      "[('Blob_N2_y-15', 0.4230769230769231), ('Blob_N1_y0', 0.6089743589743589), ('Blob_N1_y-45', 0.8), ('Blob_N2_y-30', 0.5769230769230769), ('Blob_N2_y0', 0.6209150326797386), ('Blob_N1_y-60', 0.7692307692307693), ('Blob_N2_y15', 0.38461538461538464), ('Blob_N2_y30', 0.48), ('Blob_N1_y30', 0.6153846153846154), ('Blob_N1_y15', 0.56), ('Blob_N1_y-30', 0.6538461538461539), ('Blob_N1_y-15', 0.7692307692307693), ('Blob_N2_y-45', 0.5), ('Blob_N2_y-60', 0.5769230769230769), ('Blob_N2_y45', 0.34615384615384615), ('Blob_N1_y45', 0.7037037037037037), ('Blob_N1_y60', 0.48), ('Blob_N2_y60', 0.5)]\n",
      "... Plotting stats by transform ...\n"
     ]
    }
   ],
   "source": [
    "# Process all new sessions:\n",
    "processed_sessions = process_sessions_mp(new_sessions, session_info,\n",
    "                                         output_figdir=output_figdir,\n",
    "                                         nprocesses=4,\n",
    "                                         ignore_flags=ignore_flags,\n",
    "                                         response_types=response_types,\n",
    "                                         outcome_types=outcome_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AG2] ~~~ processing complete! ~~~\n"
     ]
    }
   ],
   "source": [
    "# Update animal sessions dict:\n",
    "for datestr, S in processed_sessions.items():\n",
    "    animal.sessions.update({datestr: S})\n",
    "\n",
    "# Save to disk:\n",
    "try:\n",
    "    with open(animal_datafile, 'wb') as f:\n",
    "        pkl.dump(animal, f, protocol=pkl.HIGHEST_PROTOCOL)\n",
    "except PicklingError:\n",
    "    print(\"Unable to pkl: New sessions are not the same class as old sessions.\")\n",
    "    print(\"Reprocessing %i old sessions...\" % len(processed_sessions))\n",
    "    for datestr in old_sessions:\n",
    "        session_meta = session_info[datestr]\n",
    "        S = process_session(session_meta)\n",
    "        animal.sessions[datestr] = S\n",
    "        \n",
    "    with open(animal_datafile, 'wb') as f:\n",
    "        pkl.dump(animal, f, protocol=pkl.HIGHEST_PROTOCOL)\n",
    "\n",
    "print(\"[%s] ~~~ processing complete! ~~~\" % animal.animalid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'session': '20151119', 'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_151119.mwk'], 'animal': 'AG2'}\n",
      "***** Parsing trials *****\n",
      "... Getting session summary ...\n",
      "... Getting stimulus counts ...\n",
      "{'session': '20151118', 'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_151118.mwk'], 'animal': 'AG2'}\n",
      "***** Parsing trials *****\n",
      "... Getting session summary ...\n",
      "... Getting stimulus counts ...\n",
      "{'session': '20151120', 'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_151120.mwk'], 'animal': 'AG2'}\n",
      "***** Parsing trials *****\n",
      "N total response events:  0\n",
      "N total outcome events:  0\n",
      "Found and removed 0 orphan stimulus events in file /n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_151120.mwk\n",
      "N valid trials: 0\n",
      "... Getting session summary ...\n",
      "... Getting stimulus counts ...\n"
     ]
    }
   ],
   "source": [
    "# Reprocess buggy datafiles:\n",
    "\n",
    "# processed_sessions = {}\n",
    "# for datestr in new_sessions:\n",
    "#     session_meta = session_info[datestr]\n",
    "#     S = process_session(session_meta, \n",
    "#                         output_figdir=output_figdir,\n",
    "#                         ignore_flags=ignore_flags,\n",
    "#                         response_types=response_types, \n",
    "#                         outcome_types=outcome_types)\n",
    "#     processed_sessions[datestr] = S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save processed sessions to animal object in case MP errors out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 192 processed sessions in tmp dir.\n",
      "[AG2] ~~~ processed session update complete! ~~~\n"
     ]
    }
   ],
   "source": [
    "tmp_processed_sessions = glob.glob(os.path.join(output_figdir, 'tmp_files', 'proc_%s*.pkl' % animal.animalid))\n",
    "print(\"Found %i processed sessions in tmp dir.\" % len(tmp_processed_sessions))\n",
    "\n",
    "for tmpfile in tmp_processed_sessions:\n",
    "    with open(tmpfile, 'rb') as f:\n",
    "        tmpS = pkl.load(f)\n",
    "    datestr = os.path.splitext(os.path.split(tmpfile)[-1])[0].split('_')[2]\n",
    "    #print datestr\n",
    "    animal.sessions.update({datestr: tmpS})\n",
    "\n",
    "\n",
    "\n",
    "# Save to disk:\n",
    "try:\n",
    "    with open(animal_datafile, 'wb') as f:\n",
    "        pkl.dump(animal, f, protocol=pkl.HIGHEST_PROTOCOL)\n",
    "except PicklingError:\n",
    "    print(\"Unable to pkl: New sessions are not the same class as old sessions.\")\n",
    "    print(\"Reprocessing %i old sessions...\" % len(processed_sessions))\n",
    "    for datestr in old_sessions:\n",
    "        session_meta = session_info[datestr]\n",
    "        S = process_session(session_meta)\n",
    "        animal.sessions[datestr] = S\n",
    "        \n",
    "    with open(animal_datafile, 'wb') as f:\n",
    "        pkl.dump(animal, f, protocol=pkl.HIGHEST_PROTOCOL)\n",
    "\n",
    "print(\"[%s] ~~~ processed session update complete! ~~~\" % animal.animalid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking funky files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Event before 7216099 was missing required code, time, and/or value\n"
     ]
    }
   ],
   "source": [
    "fn = '/media/julianarhee/BK/mworks_data/AG/AG2_150803.mwk'\n",
    "df = pymworks.open(fn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response types: ['Announce_AcquirePort1', 'Announce_AcquirePort3', 'ignore']\n",
      "outcome_types: ['success', 'ignore', 'failure']\n"
     ]
    }
   ],
   "source": [
    "print \"response types:\", response_types\n",
    "print \"outcome_types:\", outcome_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Announce_AcquirePort1', 'Announce_AcquirePort3', 'ignore']\n",
      "['success', 'ignore', 'failure']\n",
      "N total response events:  0\n",
      "N total outcome events:  0\n",
      "Found and removed 0 orphan stimulus events in file /media/julianarhee/BK/mworks_data/AG/AG2_150803.mwk\n",
      "N valid trials: 0\n"
     ]
    }
   ],
   "source": [
    "trials, flags = parse_trials(df, response_types=response_types, ignore_flags=ignore_flags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.895642"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boundary = get_run_time(df)\n",
    "(boundary[1] - boundary[0]) /1E6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Event[code=5, name=#state_system_mode, time=422098815072, value=0],\n",
       " Event[code=5, name=#state_system_mode, time=422098998966, value=0],\n",
       " Event[code=5, name=#state_system_mode, time=422131902902, value=2],\n",
       " Event[code=5, name=#state_system_mode, time=422131902909, value=2],\n",
       " Event[code=5, name=#state_system_mode, time=422133798544, value=1],\n",
       " Event[code=5, name=#state_system_mode, time=422133799168, value=0],\n",
       " Event[code=5, name=#state_system_mode, time=422135401853, value=2],\n",
       " Event[code=5, name=#state_system_mode, time=422135401859, value=2],\n",
       " Event[code=5, name=#state_system_mode, time=428988902033, value=1],\n",
       " Event[code=5, name=#state_system_mode, time=428988902618, value=0]]"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.get_events('#state_system_mode')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing / debugging Session objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150314.mwk\n"
     ]
    }
   ],
   "source": [
    "curr_session = 20150314 #20160623 #session_list[pre_morphs] # 20150211\n",
    "\n",
    "datestr = session_list[session_list.index(curr_session)]\n",
    "dfn = [f for f in raw_fns if animalid in f and str(datestr)[2:] in f][0]\n",
    "print dfn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Announce_AcquirePort1', 'Announce_AcquirePort3', 'ignore']\n",
      "['success', 'ignore', 'failure']\n",
      "N total response events:  1051\n",
      "N total outcome events:  1051\n",
      "Found and removed 110 orphan stimulus events in file /n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_160623.mwk\n",
      "N valid trials: 941\n"
     ]
    }
   ],
   "source": [
    "# df = pymworks.open(dfn)\n",
    "# trials, flags = parse_trials(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Announce_AcquirePort1', 'Announce_AcquirePort3', 'ignore']\n",
      "['success', 'ignore', 'failure']\n",
      "N total response events:  335\n",
      "N total outcome events:  335\n",
      "Found and removed 57 orphan stimulus events in file /n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150314.mwk\n",
      "N valid trials: 278\n"
     ]
    }
   ],
   "source": [
    "S = Session(dfn)\n",
    "S.parse_trials(response_types=['Announce_AcquirePort1', 'Announce_AcquirePort3', 'ignore'], \\\n",
    "                 outcome_types = ['success', 'ignore', 'failure'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "S.get_counts_by_stimulus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Blob_N2_CamRot_y0', 'Blob_N1_CamRot_y0']\n"
     ]
    }
   ],
   "source": [
    "# Check if there are morphs also:\n",
    "morph_list = [s for s in S.stats.keys() if 'morph' in s]\n",
    "if len(morph_list) > 0:\n",
    "    stimulus_list = [s for s in S.stats.keys() if s not in morph_list]\n",
    "else:\n",
    "    stimulus_list = S.stats.keys()\n",
    "print stimulus_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "values = [('%s_%s' % (stim.split('_')[1], stim.split('_')[3]), \\\n",
    "                       S.stats[stim]['nsuccess']/float(S.stats[stim]['ntrials'])) for stim in stimulus_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('N2_y0', 0.9496402877697842), ('N1_y0', 0.9136690647482014)]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['morph0', 'morph1', 'morph3', 'morph5', 'morph6', 'morph7', 'morph8', 'morph9', 'morph12', 'morph13', 'morph10', 'morph11', 'morph16', 'morph14', 'morph15', 'morph2', 'morph4']\n"
     ]
    }
   ],
   "source": [
    "#stimulus_list = S.stimuli\n",
    "stimulus_list = [s for s in S.stats.keys() if 'morph' in s]\n",
    "\n",
    "print stimulus_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = [('morph_%s' % (stim.split('morph')[1]), \\\n",
    "                       S.stats[stim]['nchoose1']/float(S.stats[stim]['ntrials'])) for stim in stimulus_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('morph_0', 0.0),\n",
       " ('morph_1', 0.0),\n",
       " ('morph_3', 0.0),\n",
       " ('morph_5', 0.0),\n",
       " ('morph_6', 0.0),\n",
       " ('morph_7', 0.0),\n",
       " ('morph_8', 0.14285714285714285),\n",
       " ('morph_9', 0.14285714285714285),\n",
       " ('morph_12', 0.5714285714285714),\n",
       " ('morph_13', 0.875),\n",
       " ('morph_10', 0.375),\n",
       " ('morph_11', 0.5),\n",
       " ('morph_16', 1.0),\n",
       " ('morph_14', 0.625),\n",
       " ('morph_15', 0.7142857142857143),\n",
       " ('morph_2', 0.0),\n",
       " ('morph_4', 0.14285714285714285)]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare session numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20150202 20150203 20150204 20150205 20150206 20150207 20150208 20150209\n",
      " 20150210 20150211]\n"
     ]
    }
   ],
   "source": [
    "dates = np.arange(all_sessions[0], all_sessions[-1])\n",
    "print dates[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_list = ['r', 'g', 'b']\n",
    "pl.figure(figsize=(20,5))\n",
    "for ai, animal in enumerate(sessions.keys()):\n",
    "    session_list = sessions[animalid]\n",
    "    pl.scatter([i for i in np.arange(len(dates))], [1+ai if dt in session_list else 0 for dt in dates], color=color_list[ai])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_161130.mwk']\n"
     ]
    }
   ],
   "source": [
    "datestr = session_list[-10]\n",
    "dfn = [f for f in raw_fns if animalid in f and str(datestr)[2:] in f] # saved datestr is YYMMDD.mwk\n",
    "print dfn\n",
    "dfn = dfn[0]\n",
    "df = pymworks.open(dfn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "codec = df.get_codec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "codec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.get_events('TooFast_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstarts = [t for t in df.get_events('Announce_TrialStart') if t.value==1]\n",
    "tends = [t for t in df.get_events('Announce_TrialEnd') if t.value==1]\n",
    "print len(tstarts)\n",
    "print len(tends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "446+447+37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
