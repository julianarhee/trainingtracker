{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import pymworks\n",
    "import re\n",
    "import datautils\n",
    "import copy\n",
    "import math\n",
    "import time\n",
    "\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pylab as pl\n",
    "import cPickle as pkl\n",
    "from cPickle import PicklingError\n",
    "\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some standard formatting functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "\n",
    "def natural_keys(text):\n",
    "    return [ atoi(c) for c in re.split('(\\d+)', text) ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_datafile_name(dfn):\n",
    "    fn = os.path.splitext(os.path.split(dfn)[-1])[0]\n",
    "    fparts = fn.split('_')\n",
    "\n",
    "    assert len(fparts) == 2, \"*Warning* Unknown naming fmt: %s\" % str(fparts)\n",
    "    animalid = fparts[0]\n",
    "    datestr = fparts[1]\n",
    "\n",
    "    # Make sure no exra letters are in the datestr (for parta, b, etc.)\n",
    "    if not datestr.isdigit():\n",
    "        datestr = re.split(r'\\D', datestr)[0] # cut off any letter suffix\n",
    "    if len(datestr) == 6:\n",
    "        session = '20%s' % datestr \n",
    "    elif len(datestr) == 8:\n",
    "        session = datestr \n",
    "\n",
    "    return animalid, session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File parsing functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_run_time(df):\n",
    "    state_modes = df.get_events('#state_system_mode')\n",
    "    run_bounds = None\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            running = next(d for d in state_modes if d.value==2)\n",
    "            start_time = running.time\n",
    "            strt = state_modes.index(running)\n",
    "        except StopIteration:\n",
    "            return run_bounds\n",
    "\n",
    "        try:\n",
    "            stopping = next(d for d in state_modes[strt:] if d.value != 2) \n",
    "            end_time = stopping.time\n",
    "            stp = state_modes.index(stopping)\n",
    "        except StopIteration:\n",
    "            end_time = df.get_maximum_time()\n",
    "            stp = 0\n",
    "\n",
    "        if run_bounds is None:\n",
    "            run_bounds = []\n",
    "        \n",
    "        run_bounds.append((start_time, end_time))\n",
    "\n",
    "        # Check if there are additional run chunks:\n",
    "        remaining_state_evs = state_modes[stp:]\n",
    "        additional_starts = [s for s in remaining_state_evs if s.value == 2]\n",
    "        if len(additional_starts) > 0:\n",
    "            state_modes = remaining_state_evs\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "\n",
    "    return run_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blacklisttests = [\n",
    "#     #lambda s: (('name' in s.keys()) and (s['name'] == 'pixel clock')),\n",
    "#     lambda s: (('type' in s.keys()) and (s['type'] == 'blankscreen')),\n",
    "#     ]\n",
    "\n",
    "# def to_stims(events, as_dicts=True, blacklist=None):\n",
    "#     if blacklist is None:\n",
    "#         blacklist = blacklisttests\n",
    "#     if not isinstance(blacklist, (tuple, list)):\n",
    "#         blacklist = (blacklist, )\n",
    "#     stims = []\n",
    "#     onscreen = []\n",
    "#     for e in sorted(events, key=lambda e: e.time):\n",
    "#         if e.value is None:\n",
    "#             logging.warning(\"Encountered event with value == None\")\n",
    "#             if onscreen != {}:\n",
    "#                 logging.error(\"Event.value == None with items on screen\")\n",
    "#             continue\n",
    "#         current = []\n",
    "#         if hasattr(e.value, '__getitem__'):\n",
    "#             stimulus = None\n",
    "#             pixelclock = None\n",
    "#             for stim in e.value:\n",
    "#                 if not isinstance(stim, dict) or \\\n",
    "#                         any([t(stim) for t in blacklist]):\n",
    "#                     continue\n",
    "#                 if ('name' in stim.keys()) and (stim['name'] == 'pixel clock'):\n",
    "#                     pixelclock = stim\n",
    "#                 else:\n",
    "#                     if stimulus is not None:\n",
    "#                         logging.warning(\n",
    "#                             \"Two stimuli onscreen: %s, %s\"\n",
    "#                             % (stimulus, stim))\n",
    "#                     stimulus = stim\n",
    "#             if stimulus is not None:\n",
    "#                 current.append(pymworks.events.display.Stimulus(e.time, stimulus, pixelclock))\n",
    "#         newstims, onscreen = pymworks.events.display.find_stims(onscreen, current, e.time)\n",
    "#         stims += newstims\n",
    "#     if as_dicts:\n",
    "#         return [s.to_dict() for s in stims]\n",
    "#     return stims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_trials(stim_display_events, outcome_events, outcome_key='outcome',\n",
    "              remove_unknown=True,\n",
    "              duration_multiplier=2, stim_blacklists=None):\n",
    "    \"\"\"\n",
    "    If remove_unknown, any trials where a corresponding outcome_event cannot\n",
    "    be found will be removed.\n",
    "    If duration_multiplier is not None, to_trials will check to see if the\n",
    "    outcome event occured within duration_multiplier * duration microseconds\n",
    "    of the trial start. If the outcome event occured later, the trial outcome\n",
    "    will be marked as unknown.\n",
    "    \"\"\"\n",
    "    if (len(outcome_events) == 0) or (len(stim_display_events) == 0):\n",
    "        return []\n",
    "    assert hasattr(outcome_events[0], 'name')\n",
    "\n",
    "    trials = pymworks.events.display.to_stims(stim_display_events, as_dicts=True,\n",
    "                      blacklist=stim_blacklists)\n",
    "\n",
    "    if (len(trials) == 0):\n",
    "        return []\n",
    "\n",
    "    outcomes = pymworks.events.utils.sync(outcome_events, trials,\n",
    "                          direction=1, mkey=lambda x: x['time'])\n",
    "\n",
    "    assert len(trials) == len(outcomes)\n",
    "    unknowns = []\n",
    "    if duration_multiplier is None:\n",
    "        dtest = lambda t, o: True\n",
    "    else:\n",
    "        dtest = lambda t, o: \\\n",
    "            o.time < (t['time'] + t['duration'] * duration_multiplier)\n",
    "    for i in xrange(len(trials)):\n",
    "        if (outcomes[i] is not None) and dtest(trials[i], outcomes[i]):\n",
    "            trials[i]['%s' % outcome_key] = outcomes[i].name\n",
    "            trials[i]['%s_time' % outcome_key] = outcomes[i].time\n",
    "        else:\n",
    "            if remove_unknown:\n",
    "                unknowns.append(i)\n",
    "            else:\n",
    "                trials[i]['%s' % outcome_key] = 'unknown'\n",
    "                trials[i]['%s_time' % outcome_key] = 'unknown'\n",
    "\n",
    "    # remove trials with 'unknown' outcome, in reverse\n",
    "    for u in unknowns[::-1]:\n",
    "        del trials[u]\n",
    "\n",
    "    return trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_trials(dfn, response_types=['Announce_AcquirePort1', 'Announce_AcquirePort3', 'ignore'], \\\n",
    "                 outcome_types = ['success', 'ignore', 'failure'],\\\n",
    "                 ignore_flags=[], remove_orphans=True):\n",
    "\n",
    "    print \"***** Parsing trials *****\"\n",
    "    df = pymworks.open(dfn)\n",
    "    \n",
    "    if ignore_flags is None:\n",
    "        codec = df.get_codec()\n",
    "        ignore_flags = []\n",
    "        all_flags = [f for f in codec.values() if 'Flag' in f or 'flag' in f]\n",
    "        for fl in all_flags:\n",
    "            evs = df.get_events(fl)\n",
    "            vals = list(set([v.value for v in evs]))\n",
    "            if len(vals) > 1 or len(evs) > 5:\n",
    "                ignore_flags.append(fl)\n",
    "        \n",
    "    # Get run bounds:\n",
    "    bounds = get_run_time(df)\n",
    "    if bounds is None:\n",
    "        return None, None, df\n",
    "\n",
    "    trials = []; flag_list = []; flags = {};\n",
    "    for bound in bounds:\n",
    "        \n",
    "        if (bound[1]-bound[0])/1E6 < 2.0:\n",
    "            continue\n",
    "\n",
    "        # Get display events:\n",
    "        tmp_devs = df.get_events('#stimDisplayUpdate')                     \n",
    "        tmp_devs = [i for i in tmp_devs if bound[0] <= i['time']<= bound[1]] \n",
    "\n",
    "        # Get behavior flags:\n",
    "        codec = df.get_codec()\n",
    "        all_flags = [f for f in codec.values() if 'Flag' in f or 'flag' in f]\n",
    "        flag_names = [f for f in all_flags if f not in ignore_flags]\n",
    "        tmp_flags = dict((flag, None) for flag in flag_names)\n",
    "        for flag in flag_names:\n",
    "            if flag == 'FlagNoFeedbackInCurrentTrial': continue\n",
    "            found_values = [e.value for e in df.get_events(flag) if bound[0] <= e.time <=bound[1]]\n",
    "            if (len(found_values) > 1) or (len(list(set(found_values)))) > 1:\n",
    "                print(\"More than 1 value found for flag: %s\" % flag)\n",
    "                tmp_flags[flag] = int(found_values[-1])\n",
    "            elif (len(found_values) == 1) or (len(list(set(found_values)))) == 1:\n",
    "                tmp_flags[flag] = int(found_values[0])\n",
    "            else:\n",
    "                tmp_flags.pop(flag)\n",
    "        \n",
    "        # Add current flag values to flags list:\n",
    "        flag_list.append(tmp_flags)\n",
    "        \n",
    "        # Add boundary time to flag info:\n",
    "        tmp_flags.update({'run_bounds': bound})\n",
    "\n",
    "        \n",
    "        \n",
    "        # Check for valid response types and get all response events:\n",
    "        response_types = [r for r in response_types if r in codec.values()]\n",
    "        response_evs = [e for e in df.get_events(response_types) if (bound[0] < e['time'] < bound[1]) \\\n",
    "                        and e.value!=0]\n",
    "        #responses = pymworks.events.utils.sync(response_evs, trials, direction=1, mkey=lambda x: x['time'])\n",
    "\n",
    "        # Convert to trials: match stimulus events and response events:\n",
    "        outcome_key = 'response'\n",
    "        responses = to_trials(tmp_devs, response_evs, outcome_key=outcome_key,\n",
    "                                                   duration_multiplier=2.0,\n",
    "                                                   stim_blacklists=None,\n",
    "                                                   remove_unknown=False)\n",
    "        #print response_types\n",
    "\n",
    "\n",
    "        # Get OUTCOMES:\n",
    "        #print outcome_types\n",
    "    #     outcome_evs = [e for e in df.get_events(outcome_types) if boundary[0] <= e['time']<= boundary[1] and e.value!=0] \n",
    "    #     outcomes = pymworks.events.display.to_trials(tmp_devs, outcome_evs,\n",
    "    #                                                duration_multiplier=1.0,\n",
    "    #                                                stim_blacklists=None,\n",
    "    #                                                remove_unknown=False)\n",
    "\n",
    "        # **sync outcome events to response events as master:\n",
    "        outcome_evs = [e for e in df.get_events(outcome_types) if (bound[0] < e['time'] < bound[1]) and e.value!=0]\n",
    "        outcomes = pymworks.events.utils.sync(outcome_evs, responses, direction=1, mkey=lambda x: x['response_time'])\n",
    "\n",
    "        print \"N total response events: \", len(responses)\n",
    "        print \"N total outcome events: \", len(outcomes)\n",
    "\n",
    "        assert len(responses) == len(outcomes), \"**ERROR:  N responses != N outcomes\"\n",
    "        tmp_trials = copy.copy(responses)\n",
    "        for trial_ix, (response, outcome) in enumerate(zip(responses, outcomes)):\n",
    "            if outcome is not None:\n",
    "                tmp_trials[trial_ix].update({'outcome': outcome.name, 'outcome_time': outcome.time}) #['outcome']})\n",
    "            else:\n",
    "                tmp_trials[trial_ix].update({'outcome': 'unknown'})\n",
    "\n",
    "        # Get rid of display events without known outcome within 'duration_multiplier' time\n",
    "        if remove_orphans:                                                  \n",
    "            orphans = [(i,x) for i,x in enumerate(tmp_trials) if\\\n",
    "                        x['outcome']=='unknown' or x['%s' % outcome_key]=='unknown']\n",
    "            tmp_trials = [t for t in tmp_trials if not t['outcome']=='unknown']\n",
    "            tmp_trials = [t for t in tmp_trials if not t['%s' % outcome_key]=='unknown']\n",
    "\n",
    "            print \"Found and removed %i orphan stimulus events in file %s\" % (len(orphans), df.filename)\n",
    "            print \"N valid trials: %i\" % len(tmp_trials)\n",
    "        \n",
    "        # Add current trials in chunk to trials list:\n",
    "        trials.extend(tmp_trials)\n",
    "\n",
    "    # Reformat \"name\" param for readability:\n",
    "    if len(trials) == 0:\n",
    "        return trials, flags, df\n",
    "    \n",
    "    for t in trials:\n",
    "        assert t['response_time'] < t['outcome_time'], \"**ERROR: Mismatch in response/outcome alignment\"\n",
    "        stimname = t['name']\n",
    "        t['name'] = stimname.split('.png')[0]\n",
    "    \n",
    "    # Combine all flag states:\n",
    "    for fi, flag_dict in enumerate(flag_list):\n",
    "        if fi == 0:\n",
    "            flags = copy.copy(flag_dict)\n",
    "        else:\n",
    "            for flag_name, flag_value in flag_dict.items():\n",
    "                existing_value = flags[flag_name] #.value()\n",
    "                if flag_value == existing_value:\n",
    "                    continue\n",
    "                if not isinstance(flags[flag_name], list):\n",
    "                    flags[flag_name] = list(flags[flag_name])\n",
    "                flags[flag_name].append(flag_value)\n",
    "                \n",
    "                \n",
    "    return trials, flags, df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parse manually using 'next' isntead of pymworks utils:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pos_x': 0.0, 'pos_y': 0.0, 'name': 'Blob_N2_CamRot_y0.png 1', 'filename': '/var/folders/bq/d_40rj9j1slfyy_dz1h7_7p80000gn/T/MWorks/Experiment Cache/_Users_labuser_Downloads_RatBehaviorGeneral_Behavior_3Dtransforms_2way_blobs/tmp/Blobs_TrainingRatsD1D2/Blob_N1_CamRot_y0.png', 'file_hash': '3c0f591fcbbe5741dbb1b2982cee3e696603f72d', 'duration': 799743, 'size_x': 69.87999725341797, 'size_y': 69.87999725341797, 'time': 187516752582, 'action': 'draw', 'rotation': 0.0, 'type': 'image'}\n",
      "N valid trials: 805\n"
     ]
    }
   ],
   "source": [
    "boundary = get_run_time(df)\n",
    "\n",
    "devs = [e for e in df.get_events('#stimDisplayUpdate') if boundary[0] < e['time'] < boundary[1] and e.value!=0]\n",
    "\n",
    "toofast_time = df.get_events('TooFast_time')[-1].value\n",
    "#print toofast_time\n",
    "\n",
    "\n",
    "blacklisttests = [\n",
    "    #lambda s: (('name' in s.keys()) and (s['name'] == 'pixel clock')),\n",
    "    lambda s: (('type' in s.keys()) and (s['type'] == 'blankscreen')),\n",
    "    ]\n",
    "\n",
    "stims = pymworks.events.display.to_stims(devs, as_dicts=True,\n",
    "                  blacklist=blacklisttests)\n",
    "\n",
    "# if \"aborted\" not in response types, check that all durations are > toofast time:\n",
    "stims = [t for t in stims if t['duration'] > toofast_time] #and t['duration'] >= stim_time]\n",
    "#print len(stims)\n",
    "\n",
    "print stims[0]\n",
    "\n",
    "response_types = ['Announce_AcquirePort1', 'Announce_AcquirePort3', 'ignore']\n",
    "response_evs = [e for e in df.get_events(response_types) if boundary[0] < e['time'] < boundary[1] and e.value!=0]\n",
    "response_evs = sorted(response_evs, key=lambda x: x.time)\n",
    "\n",
    "outcome_evs = [e for e in df.get_events(outcome_types) if boundary[0] < e['time'] < boundary[1] and e.value!=0]\n",
    "outcome_evs = sorted(outcome_evs, key=lambda x: x.time)\n",
    "\n",
    "orphan_stim = []\n",
    "response_ix = 0\n",
    "outcome_ix = 0\n",
    "for trial_ix, stim in enumerate(sorted(stims, key=lambda x: x['time'])):\n",
    "    try:\n",
    "        if trial_ix == len(stims)-1:\n",
    "            curr_response = next(ev for ev in response_evs[response_ix:] if ev.time > stim['time'])\n",
    "            curr_outcome = next(ev for ev in outcome_evs[outcome_ix:] if ev.time > curr_response.time)\n",
    "        else:\n",
    "            curr_response = next(ev for ev in response_evs[response_ix:] if ev.time > stim['time'] \\\n",
    "                                 and ev.time < stims[trial_ix+1]['time'])\n",
    "            curr_outcome = next(ev for ev in outcome_evs[outcome_ix:] if ev.time > curr_response.time \\\n",
    "                                 and ev.time < stims[trial_ix+1]['time'])\n",
    "            \n",
    "        stim.update({'response': curr_response.name, 'response_time': curr_response.time,\n",
    "                     'outcome': curr_outcome.name})\n",
    "        \n",
    "        response_ix = response_evs.index(curr_response) + 1\n",
    "        outcome_ix = outcome_evs.index(curr_outcome) + 1\n",
    "\n",
    "    except StopIteration:\n",
    "        orphan_stim.append(trial_ix)\n",
    "        #print trial\n",
    "\n",
    "\n",
    "valid_trials = [i for i in np.arange(0, len(stims)) if i not in orphan_stim]\n",
    "trials = [stim for stim_ix, stim in enumerate(stims) if stim_ix in valid_trials]\n",
    "print \"N valid trials: %i\" % len(trials)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[t for t, trial in enumerate(trials) if trial['outcome'] is None or trial['response'] is None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Announce_AcquirePort1', 'Announce_AcquirePort3', 'ignore']\n",
      "['success', 'ignore', 'failure']\n",
      "N total response events:  1358\n",
      "N total outcome events:  1358\n",
      "Found and removed 216 orphan stimulus events in file /n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_161130.mwk\n",
      "N valid trials: 1142\n"
     ]
    }
   ],
   "source": [
    "trials, flags = parse_trials(dfn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check that stim - response - outcome are correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'action': 'draw',\n",
       " 'duration': 799743,\n",
       " 'file_hash': '3c0f591fcbbe5741dbb1b2982cee3e696603f72d',\n",
       " 'filename': '/var/folders/bq/d_40rj9j1slfyy_dz1h7_7p80000gn/T/MWorks/Experiment Cache/_Users_labuser_Downloads_RatBehaviorGeneral_Behavior_3Dtransforms_2way_blobs/tmp/Blobs_TrainingRatsD1D2/Blob_N1_CamRot_y0.png',\n",
       " 'name': 'Blob_N2_CamRot_y0.png 1',\n",
       " 'outcome': 'failure',\n",
       " 'pos_x': 0.0,\n",
       " 'pos_y': 0.0,\n",
       " 'response': 'Announce_AcquirePort3',\n",
       " 'response_time': 187517531099,\n",
       " 'rotation': 0.0,\n",
       " 'size_x': 69.87999725341797,\n",
       " 'size_y': 69.87999725341797,\n",
       " 'time': 187516752582,\n",
       " 'type': 'image'}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blob1: 0 incorrect successes\n",
      "Blob2: 0 incorrect successes\n",
      "N ignores: 3\n"
     ]
    }
   ],
   "source": [
    "incorrect_successes = [t for t in trials if 'Blob_N1_CamRot_y' in t['name'] \\\n",
    "                         and t['outcome']=='Announce_AcquirePort3' \\\n",
    "                         and t['result'] != 'success']\n",
    "print \"Blob1: %i incorrect successes\" % len(incorrect_successes)\n",
    "\n",
    "incorrect_successes = [t for t in trials if 'Blob_N2_CamRot_y' in t['name'] \\\n",
    "                         and t['outcome']=='Announce_AcquirePort1' \\\n",
    "                         and t['result'] != 'success']\n",
    "print \"Blob2: %i incorrect successes\" % len(incorrect_successes)\n",
    "\n",
    "\n",
    "ignore_trials = [t for t in trials if t['outcome'] == 'ignore' or t['response'] == 'ignore']\n",
    "print \"N ignores: %i\" % len(ignore_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Event[code=192, name=ignore, time=187172008460, value=1],\n",
       " Event[code=192, name=ignore, time=187172189127, value=1],\n",
       " Event[code=192, name=ignore, time=187436297574, value=1],\n",
       " Event[code=192, name=ignore, time=188145252478, value=1],\n",
       " Event[code=192, name=ignore, time=188174609211, value=1],\n",
       " Event[code=192, name=ignore, time=193875666213, value=1]]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.get_events('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test trial and event parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.get_events('TooFast_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.get_events('StimulusPresentation_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codec = df.get_codec()\n",
    "ignore_flags = []\n",
    "all_flags = [f for f in codec.values() if 'Flag' in f or 'flag' in f]\n",
    "for fl in all_flags:\n",
    "    evs = df.get_events(fl)\n",
    "    vals = list(set([v.value for v in evs]))\n",
    "    if len(vals) > 1 or len(evs) > 5:\n",
    "        ignore_flags.append(fl)\n",
    "ignore_flags\n",
    "\n",
    "# If there is no \"abort\" use \"Announce_TrialEnd\" -- these should be \"aborted\" trials:\n",
    "#resp_types=['success', 'failure', 'ignore'] #, 'Announce_TrialEnd']\n",
    "resp_types=['Announce_AcquirePort1', 'Announce_AcquirePort3', 'ignore'] #, 'Announce_TrialEnd']\n",
    "\n",
    "trials, flags = parse_trials(df, resp_types=resp_types, ignore_flags=ignore_flags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "successes = [d for d in df.get_events('success') if boundary[0] < d.time < boundary[1]]\n",
    "failures = [d for d in df.get_events('failure') if boundary[0] < d.time < boundary[1]]\n",
    "ignores = [d for d in df.get_events('ignore') if boundary[0] < d.time < boundary[1]]\n",
    "ntotal = sum([len(successes), len(failures), len(ignores)])\n",
    "\n",
    "print(\"Success: %i, Failure: %i, Ignore: %i\" % (len(successes), len(failures), len(ignores)))\n",
    "print(\"TOTAL: %i\" % ntotal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "successes = [t for t in trials if t['outcome'] == 'success']\n",
    "failures = [t for t in trials if t['outcome'] == 'failure']\n",
    "ignores = [t for t in trials if t['outcome'] == 'ignore']\n",
    "\n",
    "ntotal = len(trials)\n",
    "\n",
    "print(\"Success: %i, Failure: %i, Ignore: %i\" % (len(successes), len(failures), len(ignores)))\n",
    "print(\"TOTAL: %i\" % ntotal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choice_types = ['success', 'failure', 'ignore']\n",
    "aborted = [t for t in trials if t['outcome'] not in choice_types]\n",
    "print(\"Aborted: %i\" % len(aborted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_evs = [d for d in df.get_events('ignore') if boundary[0] <= d.time <= boundary[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(d.time-1903319378052 ) / 1E6 for d in ignore_evs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Identify NoFeedback Trials:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_evs = [e for e in df.get_events('FlagNoFeedbackInCurrentTrial') if boundary[0] <= e.time <=boundary[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.get_events('FlagShowStimAfterResponse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for tix, t in enumerate(trials):\n",
    "    dur_s = t['duration']/1E6\n",
    "    if dur_s < 0.38:\n",
    "        print tix, t['outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tix, trial in enumerate(trials[0:20]):\n",
    "    ttime = (trial['time'], trial['time'] + trial['duration'])\n",
    "    nofeedback = [e.value for e in df.get_events('FlagNoFeedbackInCurrentTrial') if \\\n",
    "                  ttime[0]-1000000 <= e.time <=ttime[1] ] #and e.value==1]\n",
    "    print tix, nofeedback #len(nofeedback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fb_evs[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group trials by stimulus type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_session_meta(dfns): #, resp_types=[], remove_orphans=True, n_training_phases=5):\n",
    "    \n",
    "    sessions_info = {}\n",
    "    for dfn in sorted(dfns, key=natural_keys):\n",
    "        aid, datestr = parse_datafile_name(dfn)\n",
    "\n",
    "        if datestr in sessions_info.keys():\n",
    "            if not isinstance(sessions_info[datestr]['datasource'], list):\n",
    "                sessions_info[datestr]['datasource'] = [sessions_info[datestr]['datasource']]\n",
    "            sessions_info[datestr]['datasource'].append(dfn)\n",
    "        else:\n",
    "            sessions_info[datestr] = dict()\n",
    "            sessions_info[datestr]['datasource'] = [dfn] \n",
    "            \n",
    "        sessions_info[datestr]['animal'] = aid\n",
    "        sessions_info[datestr]['session'] = datestr\n",
    "    \n",
    "    return sessions_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Session():\n",
    "    def __init__(self, session_meta):  \n",
    "        #animalid, datestr = parse_datafile_name(dfn)\n",
    "        self.name = session_meta['animal'] #animalid\n",
    "        self.session = session_meta['session'] #datestr\n",
    "        self.source = session_meta['datasource'] #dfn\n",
    "        self.experiment = None\n",
    "        self.protocol = None\n",
    "        self.server = None # session_meta['server']\n",
    "        self.trials = None\n",
    "        self.flags = None\n",
    "        self.stimuli = None\n",
    "        self.stats = None\n",
    "        self.summary = None\n",
    "        \n",
    "    def parse_trials(self, \n",
    "                     ignore_flags=None,\n",
    "                     response_types=['Announce_AcquirePort1', 'Announce_AcquirePort3', 'ignore'],\n",
    "                     outcome_types=['success', 'failure', 'ignore']):\n",
    "                    # If there is no \"abort\" use \"Announce_TrialEnd\" ? -- these should be \"aborted\" trials?\n",
    "        \n",
    "        trials = []\n",
    "        flags = {}\n",
    "        if isinstance(self.source, list) and len(self.source) > 1:\n",
    "            tmp_flags = []\n",
    "            for dfn in self.source:\n",
    "                curr_trials, curr_flags, df = parse_trials(dfn, response_types=response_types, \n",
    "                                                       outcome_types=outcome_types,\n",
    "                                                       ignore_flags=ignore_flags)\n",
    "                if curr_trials is not None:\n",
    "                    trials.extend(curr_trials)\n",
    "                    tmp_flags.append(curr_flags)\n",
    "\n",
    "            # Combine flag values across data files:\n",
    "            if len(tmp_flags) > 0:\n",
    "                flags = dict((fkey, []) for fkey in tmp_flags[0].keys())\n",
    "                for tmp_flag in tmp_flags:\n",
    "                    for flag_key, flag_value in tmp_flag.iteritems():\n",
    "                        if flag_key not in flags.keys():\n",
    "                            flags[flag_key] = []\n",
    "                        if flag_value not in flags[flag_key]:\n",
    "                            flags[flag_key].append(flag_value)\n",
    "        else:\n",
    "            # Open data file:\n",
    "            dfn = self.source[0]\n",
    "            trials, flags, df = parse_trials(dfn, response_types=response_types, \n",
    "                                         outcome_types=outcome_types,\n",
    "                                         ignore_flags=ignore_flags)\n",
    "\n",
    "        self.trials = trials\n",
    "        self.flags = flags\n",
    "\n",
    "        # Get current session server info while df open:\n",
    "        server_address = df.get_events('#serialBridgeAddress')[-1].value\n",
    "        server_name = df.get_events('#serverName')[-1].value\n",
    "        self.server =  {'address': server_address, 'name': server_name}\n",
    "        \n",
    "        # Save experiment and protocol info:\n",
    "        # [(payload_type, event_type)]:  [(4013, 1002), (2001, 1001), (4007, 1002)] # 1002:  Datafile creation\n",
    "        experiment_load = 4013 #:  Looks like which experiment file(s) loaded (.mwk)\n",
    "        protocol_load = 2001 #:  Which protocols found and which loaded\n",
    "        sys_evs = df.get_events('#systemEvent')\n",
    "        \n",
    "        # Get experiment loaded:\n",
    "        exp_evs = [v for v in sys_evs if v.value['payload_type']==experiment_load]\n",
    "        exp_path = list(set([v.value['payload']['experiment path'] for v in exp_evs]))\n",
    "        #assert len(exp_path) == 1, \"*ERROR* More than 1 experiment loaded...\"\n",
    "        #exp_path = exp_path[0].split('/Experiment Cache/')[1]\n",
    "        self.experiment_path = exp_path\n",
    "\n",
    "        # Get protocol loaded:\n",
    "        prot_evs = [v for v in sys_evs if v.value['payload_type']==protocol_load]\n",
    "        protocol = list(set([v.value['payload']['current protocol'] for v in prot_evs]))\n",
    "        #assert len(protocol) == 1, \"*ERROR* More than 1 protocol loaded...\"\n",
    "        #protocol = protocol[0]\n",
    "        self.protocol = protocol\n",
    "        \n",
    "        \n",
    "    def get_counts_by_stimulus(self):\n",
    "        print(\"... Getting stimulus counts ...\")\n",
    "        stats = None\n",
    "        if self.trials is not None:\n",
    "            by_stim = datautils.grouping.group(self.trials, 'name')\n",
    "\n",
    "            ordered_stim = sorted(by_stim.keys(), key=lambda x: x.split('_')[-1][1:])\n",
    "            #print ordered_stim\n",
    "\n",
    "            stats = dict((stim, {}) for stim in by_stim.keys())\n",
    "            for stim in by_stim.keys():\n",
    "                stats[stim]['ntrials'] = len(by_stim[stim])\n",
    "                stats[stim]['nsuccess'] = sum([1 if trial['outcome']=='success' else 0 for trial in by_stim[stim]])\n",
    "                stats[stim]['nfailure'] = sum([1 if trial['outcome']=='failure' else 0 for trial in by_stim[stim]])\n",
    "                stats[stim]['nignore'] = sum([1 if trial['outcome']=='ignore' else 0 for trial in by_stim[stim]])\n",
    "                stats[stim]['nchoose1'] = sum([1 if trial['response']=='Announce_AcquirePort1' else 0 for trial in by_stim[stim]])\n",
    "                stats[stim]['nchoose3'] = sum([1 if trial['outcome']=='Announce_AcquirePort3' else 0 for trial in by_stim[stim]])\n",
    "\n",
    "            # Save stimulus names for easy access:\n",
    "            stimulus_names = list(set([trial['name'] for trial in self.trials]))\n",
    "            self.stimuli = stimulus_names\n",
    "        \n",
    "        self.stats = stats\n",
    "\n",
    "        \n",
    "    def get_summary(self):\n",
    "        print(\"... Getting session summary ...\")\n",
    "        # Get stats by stim, if not run:\n",
    "        if self.stats is None:\n",
    "            self.get_counts_by_stimulus()\n",
    "        \n",
    "        if self.stats is not None:\n",
    "            summary_keys = ['ntrials', 'nsuccess', 'nfailure', 'nignore']\n",
    "            summary = dict((k, 0) for k in summary_keys)\n",
    "            if len(self.stats.keys()) > 0:\n",
    "                for stat in summary.keys():\n",
    "                    summary[stat] = [val[stat] for stim, val in self.stats.items()]\n",
    "            self.summary = summary\n",
    "        \n",
    "    def plot_stats_by_transform(self, output_figdir='/tmp'):\n",
    "        print(\"... Plotting stats by transform ...\")\n",
    "        stats = self.stats\n",
    "        \n",
    "        # Check if there are morphs also:\n",
    "        morph_list = [s for s in stats.keys() if 'morph' in s]\n",
    "        if len(morph_list) > 0:\n",
    "            stimulus_list = [s for s in stats.keys() if s not in morph_list]\n",
    "        else:\n",
    "            stimulus_list = stats.keys()\n",
    "            \n",
    "        # Check stimulus name:\n",
    "        blob_names = [b for b in self.stimuli if 'Blob_' in b]\n",
    "        if 'N' in blob_names[0].split('_')[1]: # this is Blob_Nx_CamRot naming scheme:\n",
    "            blob1_name = 'Blob_N1'\n",
    "            blob2_name = 'Blob_N2'\n",
    "        else:\n",
    "            blob1_name = 'Blob_1'\n",
    "            blob2_name = 'Blob_2'\n",
    "            \n",
    "        if stats is not None:\n",
    "            values = [('%s_%s' % ('_'.join(stim.split('_')[0:2]), stim.split('_')[3]), \\\n",
    "                       stats[stim]['nsuccess']/float(stats[stim]['ntrials'])) for stim in stimulus_list]\n",
    "            print values\n",
    "\n",
    "            pl.figure()\n",
    "            if 'CamRot' in stimulus_list[0]:\n",
    "                blob1 = [(int(v[0].split('_')[-1][1:]), v[1]) for v in values if blob1_name in v[0]]\n",
    "                blob2 = [(int(v[0].split('_')[-1][1:]), v[1]) for v in values if blob2_name in v[0]]\n",
    "            else:\n",
    "                blob1 = [(int(v[0].split('_')[-1]), v[1]) for v in values if blob1_name in v[0]]\n",
    "                blob2 = [(int(v[0].split('_')[-1]), v[1]) for v in values if blob2_name in v[0]]\n",
    "                \n",
    "            pl.plot([b[0] for b in sorted(blob1, key=lambda x: x[0])], \\\n",
    "                    [b[1] for b in sorted(blob1, key=lambda x: x[0])], 'ro', label=blob1_name)\n",
    "            pl.plot([b[0] for b in sorted(blob2, key=lambda x: x[0])], \\\n",
    "                    [b[1] for b in sorted(blob2, key=lambda x: x[0])], 'bo', label=blob2_name)\n",
    "            pl.legend()\n",
    "            pl.ylim(0, 1)\n",
    "            pl.title(datestr)\n",
    "            pl.savefig(os.path.join(output_figdir, '%s_%s_bystim.png' % (self.name, self.session)))\n",
    "            pl.close()\n",
    "\n",
    "    def plot_stats_by_morph(self, output_figdir='/tmp'):\n",
    "        print(\"... Plotting stats by transform ...\")\n",
    "\n",
    "        stats = self.stats\n",
    "        stimulus_list = [s for s in stats.keys() if 'morph' in s]\n",
    "            \n",
    "        if stats is not None:\n",
    "            values = [('morph_%s' % (stim.split('morph')[1]), \\\n",
    "                       stats[stim]['nchoose1']/float(stats[stim]['ntrials'])) for stim in stimulus_list]\n",
    "\n",
    "            pl.figure()\n",
    "            pchoose1 = [(int(v[0].split('_')[-1]), v[1]) for v in values]\n",
    "            pl.plot([b[0] for b in sorted(pchoose1, key=lambda x: x[0])], \\\n",
    "                    [b[1] for b in sorted(pchoose1, key=lambda x: x[0])], 'bo')\n",
    "            pl.ylim(0, 1)\n",
    "            pl.ylabel(\"perc. choose port 1)\")\n",
    "            pl.title(datestr)\n",
    "            pl.savefig(os.path.join(output_figdir, '%s_%s_morphs.png' % (self.name, self.session)))\n",
    "            pl.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Animal():\n",
    "    def __init__(self, animalid='RAT', experiment='EXPERIMENT', output_datadir='/tmp'):\n",
    "        self.animalid = animalid\n",
    "        self.experient = experiment\n",
    "        self.outdir = output_datadir\n",
    "        self.sessions = {}\n",
    "        \n",
    "    def get_sessions(self, dfns):\n",
    "        session_info = get_session_meta(dfns)\n",
    "        return session_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_session(session_meta, \n",
    "                    output_figdir='/tmp',\n",
    "                    response_types=['Announce_AcquirePort1', 'Announce_AcquirePort3', 'ignore'],\n",
    "                    outcome_types=['success', 'ignore', 'failure'],\n",
    "                    ignore_flags=None):\n",
    "    \n",
    "    S = Session(session_meta)\n",
    "    print session_meta\n",
    "    S.parse_trials(response_types=['Announce_AcquirePort1', 'Announce_AcquirePort3', 'ignore'], \\\n",
    "                 outcome_types = ['success', 'ignore', 'failure'])\n",
    "\n",
    "    S.get_summary() #S.get_counts_by_stimulus()\n",
    "\n",
    "    if S.summary is None or S.summary['ntrials'] == 0:\n",
    "        return None\n",
    "    \n",
    "    S.plot_stats_by_transform(output_figdir=output_figdir)\n",
    "\n",
    "    if any('morph' in i for i in S.stimuli):\n",
    "        S.plot_stats_by_morph(output_figdir=output_figdir)\n",
    "        \n",
    "    # Save tmp file:\n",
    "    tmp_file_dir = os.path.join(output_figdir, 'tmp_files')\n",
    "    if not os.path.exists(tmp_file_dir): os.makedirs(tmp_file_dir)\n",
    "    with open(os.path.join(tmp_file_dir, 'proc_%s_%s.pkl' % (S.name, S.session)), 'wb') as f:\n",
    "        pkl.dump(S, f, protocol=pkl.HIGHEST_PROTOCOL)\n",
    "        \n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sessions_mp(new_sessions, session_info,\n",
    "                         output_figdir='/tmp',\n",
    "                         nprocesses=1,\n",
    "                         ignore_flags=None,\n",
    "                         response_types=['Announce_AcquirePort1', 'Announce_AcquirePort3', 'ignore'],\n",
    "                         outcome_types = ['success', 'ignore', 'failure']):\n",
    "    \n",
    "    print \"SAVING FIGURES TO:\", output_figdir\n",
    "    \n",
    "    def parser(curr_sessions, session_info, ignore_flags, response_types, outcome_types, output_figdir, out_q):\n",
    "        parsed_sessions = {}\n",
    "        for datestr in curr_sessions:\n",
    "            session_meta = session_info[datestr]\n",
    "            S = process_session(session_meta, \n",
    "                                output_figdir=output_figdir,\n",
    "                                ignore_flags=ignore_flags,\n",
    "                                response_types=response_types, \n",
    "                                outcome_types=outcome_types)\n",
    "            parsed_sessions[datestr] = S\n",
    "        out_q.put(parsed_sessions)\n",
    "    \n",
    "    # Get a chunksize of sessions to process and queue for outputs:\n",
    "    out_q = mp.Queue()\n",
    "    chunksize = int(math.ceil(len(new_sessions) / float(nprocesses)))\n",
    "    procs = []\n",
    "    for i in range(nprocesses):\n",
    "        p = mp.Process(target=parser,\n",
    "                      args=(new_sessions[chunksize * i:chunksize * (i + 1)],\n",
    "                           session_info, \n",
    "                           ignore_flags,\n",
    "                           response_types,\n",
    "                           outcome_types,\n",
    "                           output_figdir,\n",
    "                           out_q))\n",
    "        procs.append(p)\n",
    "        p.start()\n",
    "        \n",
    "    # Collect all results into single dict:\n",
    "    processed_dict = {}\n",
    "    for i in range(nprocesses):\n",
    "        processed_dict.update(out_q.get())\n",
    "    \n",
    "    # Wait for all worker processes to finish:\n",
    "#     for p in procs:\n",
    "#         print \"Finished:\", p\n",
    "#         p.join()\n",
    "    TIMEOUT = 60\n",
    "    start = time.time()\n",
    "    while time.time() - start <= TIMEOUT:\n",
    "        if any([p.is_alive() for p in procs]):\n",
    "            time.sleep(.1)\n",
    "        else:\n",
    "            break # all processes complete, break\n",
    "    else:\n",
    "        # kill processes if time out\n",
    "        print(\"timed out... killing all processes.\")\n",
    "        for p in procs:\n",
    "            p.terminate()\n",
    "            p.join()\n",
    "            \n",
    "        \n",
    "    return processed_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse .mwk data files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Set sources and output dirs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set path params:\n",
    "root = '/n/coxfs01/behavior-data'\n",
    "experiment = 'threeport_morphs'\n",
    "cohort = 'AG'\n",
    "\n",
    "# Set experiment parsing vars and params:\n",
    "response_types = ['Announce_AcquirePort1', 'Announce_AcquirePort3', 'ignore']\n",
    "outcome_types = outcome_types = ['success', 'ignore', 'failure']\n",
    "ignore_flags = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving parsed datafiles to: /n/coxfs01/behavior-data/threeport_morphs/AG/processed/data\n",
      "Saving figures to: /n/coxfs01/behavior-data/threeport_morphs/AG/processed/figures\n"
     ]
    }
   ],
   "source": [
    "# Create output dirs:\n",
    "output_dir = os.path.join(root, experiment, cohort, 'processed')\n",
    "output_figdir = os.path.join(output_dir, 'figures')\n",
    "output_datadir = os.path.join(output_dir, 'data')\n",
    "if not os.path.exists(output_figdir): os.makedirs(output_figdir)\n",
    "if not os.path.exists(output_datadir): os.makedirs(output_datadir)\n",
    "\n",
    "\n",
    "print(\"Saving parsed datafiles to: %s\" % output_datadir)\n",
    "print(\"Saving figures to: %s\" % output_figdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Get list of all datafiles for each animal in cohort\n",
    "Datafile format:  ANIMALID_YYMMDD.mwk (convert datestr to YYYYMMDD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "Found 12 animals in cohort AG.\n",
      "-- first session: 20150202, last session: 20170202 --\n",
      "N sessions per animal:\n",
      "AG1: 205 sessions\n",
      "AG2: 196 sessions\n",
      "AG3: 29 sessions\n",
      "AG4: 156 sessions\n",
      "AG5: 172 sessions\n",
      "AG6: 173 sessions\n",
      "AG7: 189 sessions\n",
      "AG8: 190 sessions\n",
      "AG9: 132 sessions\n",
      "AG10: 155 sessions\n",
      "AG11: 155 sessions\n",
      "AG12: 42 sessions\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Get list of a.. raw data files:\n",
    "raw_fns = glob.glob(os.path.join(root, experiment, cohort, 'raw', '*.mwk'))\n",
    "\n",
    "sessions = {}\n",
    "for fn in raw_fns:\n",
    "    animalid, datestr = parse_datafile_name(fn)\n",
    "    if animalid not in sessions.keys():\n",
    "        sessions[animalid] = []\n",
    "    sessions[animalid].append(int(datestr))\n",
    "    \n",
    "    \n",
    "animalids = sorted(sessions.keys(), key=natural_keys)\n",
    "nsessions = [len(sessions[animal]) for animal in sorted(animalids, key=natural_keys)]\n",
    "all_sessions = sorted([int(item) for sublist in sessions.values() for item in sublist])\n",
    "\n",
    "print('----------------------------------------------')\n",
    "print(\"Found %i animals in cohort %s.\" % (len(animalids), cohort))\n",
    "print(\"-- first session: %i, last session: %i --\" % (all_sessions[0], all_sessions[-1]))\n",
    "print(\"N sessions per animal:\")\n",
    "for animalid, session_count in zip(animalids, nsessions):\n",
    "    print(\"%s: %i sessions\" % (animalid, session_count))\n",
    "print('----------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.  Process new datafiles for each animal in cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AG2:  \n",
    "# up thru 20150313 - Blob_1_RotDept_0\n",
    "# starting 20150314 -- Blob_1_CamRot_y0\n",
    "# morphs start 20160623\n",
    "\n",
    "animalid = 'AG2'\n",
    "\n",
    "session_list = sessions[animalid]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get current animal session info:\n",
    "animal = Animal(animalid=animalid, experiment=experiment, output_datadir=output_datadir)\n",
    "curr_dfns = [dfn for dfn in raw_fns if animalid == os.path.splitext(os.path.split(dfn)[-1])[0].split('_')[0] or animalid == os.path.splitext(os.path.split(dfn)[-1])[0].split('_')[1]]\n",
    "session_info = animal.get_sessions(curr_dfns)\n",
    "\n",
    "# Create animal datafile:\n",
    "animal_datafile = os.path.join(output_datadir, '%s.pkl' % animalid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'20150202': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150202.mwk'],\n",
       "  'session': '20150202'},\n",
       " '20150203': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150203.mwk'],\n",
       "  'session': '20150203'},\n",
       " '20150204': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150204.mwk'],\n",
       "  'session': '20150204'},\n",
       " '20150206': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150206.mwk'],\n",
       "  'session': '20150206'},\n",
       " '20150209': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150209.mwk'],\n",
       "  'session': '20150209'},\n",
       " '20150210': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150210.mwk'],\n",
       "  'session': '20150210'},\n",
       " '20150211': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150211.mwk'],\n",
       "  'session': '20150211'},\n",
       " '20150212': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150212.mwk'],\n",
       "  'session': '20150212'},\n",
       " '20150213': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150213.mwk'],\n",
       "  'session': '20150213'},\n",
       " '20150216': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150216.mwk'],\n",
       "  'session': '20150216'},\n",
       " '20150217': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150217.mwk'],\n",
       "  'session': '20150217'},\n",
       " '20150218': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150218.mwk'],\n",
       "  'session': '20150218'},\n",
       " '20150219': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150219.mwk'],\n",
       "  'session': '20150219'},\n",
       " '20150220': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150220.mwk'],\n",
       "  'session': '20150220'},\n",
       " '20150223': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150223.mwk'],\n",
       "  'session': '20150223'},\n",
       " '20150225': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150225.mwk'],\n",
       "  'session': '20150225'},\n",
       " '20150226': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150226.mwk'],\n",
       "  'session': '20150226'},\n",
       " '20150227': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150227.mwk'],\n",
       "  'session': '20150227'},\n",
       " '20150303': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150303.mwk'],\n",
       "  'session': '20150303'},\n",
       " '20150304': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150304.mwk'],\n",
       "  'session': '20150304'},\n",
       " '20150305': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150305.mwk'],\n",
       "  'session': '20150305'},\n",
       " '20150306': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150306.mwk'],\n",
       "  'session': '20150306'},\n",
       " '20150309': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150309.mwk'],\n",
       "  'session': '20150309'},\n",
       " '20150311': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150311.mwk'],\n",
       "  'session': '20150311'},\n",
       " '20150313': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150313.mwk'],\n",
       "  'session': '20150313'},\n",
       " '20150314': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150314.mwk'],\n",
       "  'session': '20150314'},\n",
       " '20150316': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150316.mwk'],\n",
       "  'session': '20150316'},\n",
       " '20150317': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150317.mwk'],\n",
       "  'session': '20150317'},\n",
       " '20150324': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150324.mwk'],\n",
       "  'session': '20150324'},\n",
       " '20150325': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150325.mwk'],\n",
       "  'session': '20150325'},\n",
       " '20150326': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150326.mwk'],\n",
       "  'session': '20150326'},\n",
       " '20150327': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150327.mwk'],\n",
       "  'session': '20150327'},\n",
       " '20150330': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150330.mwk'],\n",
       "  'session': '20150330'},\n",
       " '20150401': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150401.mwk'],\n",
       "  'session': '20150401'},\n",
       " '20150402': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150402.mwk'],\n",
       "  'session': '20150402'},\n",
       " '20150421': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150421.mwk'],\n",
       "  'session': '20150421'},\n",
       " '20150422': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150422.mwk'],\n",
       "  'session': '20150422'},\n",
       " '20150423': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150423.mwk'],\n",
       "  'session': '20150423'},\n",
       " '20150424': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150424.mwk'],\n",
       "  'session': '20150424'},\n",
       " '20150428': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150428.mwk'],\n",
       "  'session': '20150428'},\n",
       " '20150429': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150429.mwk'],\n",
       "  'session': '20150429'},\n",
       " '20150501': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150501.mwk'],\n",
       "  'session': '20150501'},\n",
       " '20150506': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150506.mwk'],\n",
       "  'session': '20150506'},\n",
       " '20150507': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150507.mwk'],\n",
       "  'session': '20150507'},\n",
       " '20150508': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150508.mwk'],\n",
       "  'session': '20150508'},\n",
       " '20150511': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150511.mwk'],\n",
       "  'session': '20150511'},\n",
       " '20150512': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150512.mwk'],\n",
       "  'session': '20150512'},\n",
       " '20150513': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150513.mwk'],\n",
       "  'session': '20150513'},\n",
       " '20150519': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150519.mwk'],\n",
       "  'session': '20150519'},\n",
       " '20150602': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150602.mwk'],\n",
       "  'session': '20150602'},\n",
       " '20150603': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150603.mwk'],\n",
       "  'session': '20150603'},\n",
       " '20150604': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150604.mwk'],\n",
       "  'session': '20150604'},\n",
       " '20150608': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150608.mwk'],\n",
       "  'session': '20150608'},\n",
       " '20150609': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150609.mwk'],\n",
       "  'session': '20150609'},\n",
       " '20150610': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150610.mwk'],\n",
       "  'session': '20150610'},\n",
       " '20150611': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150611.mwk'],\n",
       "  'session': '20150611'},\n",
       " '20150612': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150612.mwk'],\n",
       "  'session': '20150612'},\n",
       " '20150616': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150616.mwk'],\n",
       "  'session': '20150616'},\n",
       " '20150617': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150617.mwk'],\n",
       "  'session': '20150617'},\n",
       " '20150622': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150622.mwk'],\n",
       "  'session': '20150622'},\n",
       " '20150625': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150625.mwk'],\n",
       "  'session': '20150625'},\n",
       " '20150626': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150626.mwk'],\n",
       "  'session': '20150626'},\n",
       " '20150707': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150707.mwk'],\n",
       "  'session': '20150707'},\n",
       " '20150708': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150708.mwk'],\n",
       "  'session': '20150708'},\n",
       " '20150709': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150709.mwk'],\n",
       "  'session': '20150709'},\n",
       " '20150710': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150710.mwk'],\n",
       "  'session': '20150710'},\n",
       " '20150713': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150713.mwk'],\n",
       "  'session': '20150713'},\n",
       " '20150714': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150714.mwk'],\n",
       "  'session': '20150714'},\n",
       " '20150715': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150715.mwk'],\n",
       "  'session': '20150715'},\n",
       " '20150716': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150716.mwk'],\n",
       "  'session': '20150716'},\n",
       " '20150721': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150721.mwk'],\n",
       "  'session': '20150721'},\n",
       " '20150722': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150722.mwk'],\n",
       "  'session': '20150722'},\n",
       " '20150723': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150723.mwk'],\n",
       "  'session': '20150723'},\n",
       " '20150724': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150724.mwk'],\n",
       "  'session': '20150724'},\n",
       " '20150728': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150728.mwk'],\n",
       "  'session': '20150728'},\n",
       " '20150729': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150729.mwk'],\n",
       "  'session': '20150729'},\n",
       " '20150730': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150730.mwk'],\n",
       "  'session': '20150730'},\n",
       " '20150803': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150803.mwk'],\n",
       "  'session': '20150803'},\n",
       " '20150804': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150804.mwk'],\n",
       "  'session': '20150804'},\n",
       " '20150805': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150805.mwk'],\n",
       "  'session': '20150805'},\n",
       " '20150901': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150901.mwk'],\n",
       "  'session': '20150901'},\n",
       " '20150902': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150902.mwk'],\n",
       "  'session': '20150902'},\n",
       " '20150903': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150903.mwk'],\n",
       "  'session': '20150903'},\n",
       " '20150914': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150914.mwk'],\n",
       "  'session': '20150914'},\n",
       " '20150915': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150915.mwk'],\n",
       "  'session': '20150915'},\n",
       " '20150917': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150917.mwk'],\n",
       "  'session': '20150917'},\n",
       " '20150918': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150918.mwk'],\n",
       "  'session': '20150918'},\n",
       " '20150928': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150928.mwk'],\n",
       "  'session': '20150928'},\n",
       " '20151028': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_151028.mwk'],\n",
       "  'session': '20151028'},\n",
       " '20151029': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_151029.mwk'],\n",
       "  'session': '20151029'},\n",
       " '20151030': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_151030.mwk'],\n",
       "  'session': '20151030'},\n",
       " '20151102': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_151102.mwk'],\n",
       "  'session': '20151102'},\n",
       " '20151110': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_151110.mwk'],\n",
       "  'session': '20151110'},\n",
       " '20151112': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_151112.mwk'],\n",
       "  'session': '20151112'},\n",
       " '20151117': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_151117.mwk'],\n",
       "  'session': '20151117'},\n",
       " '20151118': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_151118.mwk'],\n",
       "  'session': '20151118'},\n",
       " '20151119': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_151119.mwk'],\n",
       "  'session': '20151119'},\n",
       " '20151120': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_151120.mwk'],\n",
       "  'session': '20151120'},\n",
       " '20151123': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_151123.mwk'],\n",
       "  'session': '20151123'},\n",
       " '20151201': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_151201.mwk'],\n",
       "  'session': '20151201'},\n",
       " '20151202': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_151202.mwk'],\n",
       "  'session': '20151202'},\n",
       " '20151203': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_151203.mwk'],\n",
       "  'session': '20151203'},\n",
       " '20151204': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_151204.mwk'],\n",
       "  'session': '20151204'},\n",
       " '20151208': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_151208.mwk'],\n",
       "  'session': '20151208'},\n",
       " '20151209': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_151209.mwk'],\n",
       "  'session': '20151209'},\n",
       " '20151215': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_151215.mwk'],\n",
       "  'session': '20151215'},\n",
       " '20151216': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_151216.mwk'],\n",
       "  'session': '20151216'},\n",
       " '20151217': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_151217.mwk'],\n",
       "  'session': '20151217'},\n",
       " '20160111': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_160111.mwk'],\n",
       "  'session': '20160111'},\n",
       " '20160113': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_160113.mwk'],\n",
       "  'session': '20160113'},\n",
       " '20160121': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_160121.mwk'],\n",
       "  'session': '20160121'},\n",
       " '20160122': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_160122.mwk'],\n",
       "  'session': '20160122'},\n",
       " '20160125': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_160125.mwk'],\n",
       "  'session': '20160125'},\n",
       " '20160126': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_160126.mwk'],\n",
       "  'session': '20160126'},\n",
       " '20160127': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_160127.mwk'],\n",
       "  'session': '20160127'},\n",
       " '20160128': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_160128.mwk'],\n",
       "  'session': '20160128'},\n",
       " '20160202': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_160202.mwk'],\n",
       "  'session': '20160202'},\n",
       " '20160203': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_160203.mwk'],\n",
       "  'session': '20160203'},\n",
       " '20160204': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_160204.mwk'],\n",
       "  'session': '20160204'},\n",
       " '20160205': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_160205.mwk'],\n",
       "  'session': '20160205'},\n",
       " '20160208': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_160208.mwk'],\n",
       "  'session': '20160208'},\n",
       " '20160209': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_160209.mwk'],\n",
       "  'session': '20160209'},\n",
       " '20160210': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_160210.mwk'],\n",
       "  'session': '20160210'},\n",
       " '20160211': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_160211.mwk'],\n",
       "  'session': '20160211'},\n",
       " '20160212': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_160212.mwk',\n",
       "   '/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_160212b.mwk'],\n",
       "  'session': '20160212'},\n",
       " '20160213': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_160213b.mwk'],\n",
       "  'session': '20160213'},\n",
       " '20160215': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_160215b.mwk'],\n",
       "  'session': '20160215'},\n",
       " '20160216': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_160216r.mwk'],\n",
       "  'session': '20160216'},\n",
       " '20160217': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_160217.mwk'],\n",
       "  'session': '20160217'},\n",
       " '20160218': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_160218.mwk'],\n",
       "  'session': '20160218'},\n",
       " '20160223': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_160223.mwk'],\n",
       "  'session': '20160223'},\n",
       " '20160225': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_160225.mwk'],\n",
       "  'session': '20160225'},\n",
       " '20160226': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_160226.mwk'],\n",
       "  'session': '20160226'},\n",
       " '20160310': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_160310.mwk'],\n",
       "  'session': '20160310'},\n",
       " '20160311': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_160311.mwk'],\n",
       "  'session': '20160311'},\n",
       " '20160314': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_160314.mwk'],\n",
       "  'session': '20160314'},\n",
       " '20160315': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_160315.mwk'],\n",
       "  'session': '20160315'},\n",
       " '20160316': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_160316.mwk'],\n",
       "  'session': '20160316'},\n",
       " '20160317': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_160317.mwk'],\n",
       "  'session': '20160317'},\n",
       " '20160318': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_160318.mwk'],\n",
       "  'session': '20160318'},\n",
       " '20160328': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_160328.mwk'],\n",
       "  'session': '20160328'},\n",
       " '20160329': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_160329.mwk'],\n",
       "  'session': '20160329'},\n",
       " '20160330': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_160330.mwk'],\n",
       "  'session': '20160330'},\n",
       " '20160331': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_160331.mwk'],\n",
       "  'session': '20160331'},\n",
       " '20160404': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_160404.mwk'],\n",
       "  'session': '20160404'},\n",
       " '20160408': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_160408.mwk'],\n",
       "  'session': '20160408'},\n",
       " '20160603': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_160603.mwk'],\n",
       "  'session': '20160603'},\n",
       " '20160604': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_160604.mwk'],\n",
       "  'session': '20160604'},\n",
       " '20160606': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_160606.mwk'],\n",
       "  'session': '20160606'},\n",
       " '20160607': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_160607.mwk'],\n",
       "  'session': '20160607'},\n",
       " '20160608': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_160608.mwk'],\n",
       "  'session': '20160608'},\n",
       " '20160609': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_160609.mwk'],\n",
       "  'session': '20160609'},\n",
       " '20160610': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_160610.mwk'],\n",
       "  'session': '20160610'},\n",
       " '20160613': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_160613.mwk'],\n",
       "  'session': '20160613'},\n",
       " '20160614': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_160614.mwk'],\n",
       "  'session': '20160614'},\n",
       " '20160615': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_160615.mwk'],\n",
       "  'session': '20160615'},\n",
       " '20160616': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_160616.mwk'],\n",
       "  'session': '20160616'},\n",
       " '20160617': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_160617.mwk'],\n",
       "  'session': '20160617'},\n",
       " '20160618': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_160618.mwk'],\n",
       "  'session': '20160618'},\n",
       " '20160620': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_160620.mwk'],\n",
       "  'session': '20160620'},\n",
       " '20160621': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_160621.mwk'],\n",
       "  'session': '20160621'},\n",
       " '20160622': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_160622.mwk'],\n",
       "  'session': '20160622'},\n",
       " '20160623': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_160623.mwk'],\n",
       "  'session': '20160623'},\n",
       " '20160624': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_160624.mwk'],\n",
       "  'session': '20160624'},\n",
       " '20160625': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_160625.mwk'],\n",
       "  'session': '20160625'},\n",
       " '20160626': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_160626.mwk'],\n",
       "  'session': '20160626'},\n",
       " '20160627': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_160627.mwk'],\n",
       "  'session': '20160627'},\n",
       " '20160628': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_160628.mwk'],\n",
       "  'session': '20160628'},\n",
       " '20160630': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_160630.mwk'],\n",
       "  'session': '20160630'},\n",
       " '20160701': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_160701.mwk'],\n",
       "  'session': '20160701'},\n",
       " '20160705': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_160705.mwk'],\n",
       "  'session': '20160705'},\n",
       " '20160706': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_160706.mwk'],\n",
       "  'session': '20160706'},\n",
       " '20161108': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_161108.mwk'],\n",
       "  'session': '20161108'},\n",
       " '20161109': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_161109.mwk'],\n",
       "  'session': '20161109'},\n",
       " '20161110': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_161110.mwk'],\n",
       "  'session': '20161110'},\n",
       " '20161114': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_161114.mwk'],\n",
       "  'session': '20161114'},\n",
       " '20161115': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_161115.mwk'],\n",
       "  'session': '20161115'},\n",
       " '20161116': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_161116.mwk'],\n",
       "  'session': '20161116'},\n",
       " '20161117': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_161117.mwk'],\n",
       "  'session': '20161117'},\n",
       " '20161118': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_161118.mwk'],\n",
       "  'session': '20161118'},\n",
       " '20161121': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_161121.mwk'],\n",
       "  'session': '20161121'},\n",
       " '20161122': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_161122.mwk'],\n",
       "  'session': '20161122'},\n",
       " '20161123': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_161123.mwk'],\n",
       "  'session': '20161123'},\n",
       " '20161128': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_161128.mwk'],\n",
       "  'session': '20161128'},\n",
       " '20161129': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_161129.mwk'],\n",
       "  'session': '20161129'},\n",
       " '20161130': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_161130.mwk'],\n",
       "  'session': '20161130'},\n",
       " '20161201': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_161201.mwk'],\n",
       "  'session': '20161201'},\n",
       " '20161202': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_161202.mwk'],\n",
       "  'session': '20161202'},\n",
       " '20161205': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_161205.mwk'],\n",
       "  'session': '20161205'},\n",
       " '20161206': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_161206.mwk'],\n",
       "  'session': '20161206'},\n",
       " '20161207': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_161207.mwk'],\n",
       "  'session': '20161207'},\n",
       " '20161208': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_161208.mwk'],\n",
       "  'session': '20161208'},\n",
       " '20161209': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_161209.mwk'],\n",
       "  'session': '20161209'},\n",
       " '20161212': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_161212.mwk'],\n",
       "  'session': '20161212'},\n",
       " '20161213': {'animal': 'AG2',\n",
       "  'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_161213.mwk'],\n",
       "  'session': '20161213'}}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[s for s, sd in session_info.items() if sd['animal'] != animalid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AG2]: Found 0 processed sessions.\n",
      "[AG2]: There are 195 out of 195 found session datafiles to process.\n"
     ]
    }
   ],
   "source": [
    "# Check if processed file exists -- load or create new.\n",
    "create_new = False\n",
    "if os.path.exists(animal_datafile):\n",
    "    try:\n",
    "        with open(animal_datafile, 'rb') as f:\n",
    "            animal = pkl.load(f)   \n",
    "    except EOFError:\n",
    "        create_new = True\n",
    "        \n",
    "if create_new:\n",
    "    animal = Animal(animalid=animalid, experiment=experiment, output_datadir=output_datadir)\n",
    "\n",
    "\n",
    "# Process new datafiles / sessions:\n",
    "old_sessions = [sesh for sesh, sobject in animal.sessions.items() if sobject is not None]\n",
    "print(\"[%s]: Found %i processed sessions.\" % (animalid, len(old_sessions)))\n",
    "all_sessions = session_info.keys()\n",
    "new_sessions = [s for s in all_sessions if s not in old_sessions]\n",
    "\n",
    "print(\"[%s]: There are %i out of %i found session datafiles to process.\" % (animal.animalid, len(new_sessions), len(all_sessions)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING FIGURES TO: /n/coxfs01/behavior-data/threeport_morphs/AG/processed/figures\n",
      "{'session': '20160317', 'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_160317.mwk'], 'animal': 'AG2'}\n",
      "***** Parsing trials *****\n",
      "{'session': '20151102', 'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_151102.mwk'], 'animal': 'AG2'}\n",
      "***** Parsing trials *****\n",
      "{'session': '20150914', 'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150914.mwk'], 'animal': 'AG2'}\n",
      "***** Parsing trials *****\n",
      "{'session': '20160614', 'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_160614.mwk'], 'animal': 'AG2'}\n",
      "***** Parsing trials *****\n",
      "N total response events:  427\n",
      "N total outcome events:  427\n",
      "Found and removed 69 orphan stimulus events in file /n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_151102.mwk\n",
      "N valid trials: 358\n",
      "... Getting session summary ...\n",
      "... Getting stimulus counts ...\n",
      "... Plotting stats by transform ...\n",
      "[('Blob_N2_y60', 0.8461538461538461), ('Blob_N2_y45', 0.9230769230769231), ('Blob_N1_y45', 0.8666666666666667), ('Blob_N1_y60', 0.9166666666666666), ('Blob_N2_y15', 1.0), ('Blob_N1_y-30', 1.0), ('Blob_N1_y-15', 1.0), ('Blob_N1_y0', 0.7972972972972973), ('Blob_N2_y30', 1.0), ('Blob_N1_y-45', 1.0), ('Blob_N2_y-45', 0.9333333333333333), ('Blob_N2_y0', 0.8831168831168831), ('Blob_N1_y30', 1.0), ('Blob_N2_y-60', 1.0), ('Blob_N1_y15', 1.0), ('Blob_N2_y-15', 0.6923076923076923), ('Blob_N1_y-60', 0.9166666666666666), ('Blob_N2_y-30', 0.7857142857142857)]\n",
      "{'session': '20150604', 'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150604.mwk'], 'animal': 'AG2'}\n",
      "***** Parsing trials *****\n",
      "N total response events:  561\n",
      "N total outcome events:  561\n",
      "Found and removed 125 orphan stimulus events in file /n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150914.mwk\n",
      "N valid trials: 436\n",
      "... Getting session summary ...\n",
      "... Getting stimulus counts ...\n",
      "... Plotting stats by transform ...\n",
      "[('Blob_N2_y60', 0.625), ('Blob_N2_y45', 0.6875), ('Blob_N1_y45', 0.9333333333333333), ('Blob_N1_y60', 0.9333333333333333), ('Blob_N2_y15', 0.6875), ('Blob_N1_y-30', 1.0), ('Blob_N1_y-15', 1.0), ('Blob_N1_y0', 0.7526881720430108), ('Blob_N2_y30', 0.8666666666666667), ('Blob_N1_y-45', 1.0), ('Blob_N2_y-45', 0.8), ('Blob_N2_y0', 0.851063829787234), ('Blob_N1_y30', 1.0), ('Blob_N2_y-60', 0.8125), ('Blob_N1_y15', 0.9375), ('Blob_N2_y-15', 0.75), ('Blob_N1_y-60', 0.9333333333333333), ('Blob_N2_y-30', 0.5)]\n",
      "{'session': '20150915', 'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150915.mwk'], 'animal': 'AG2'}\n",
      "***** Parsing trials *****\n",
      "N total response events:  911\n",
      "N total outcome events:  911\n",
      "Found and removed 84 orphan stimulus events in file /n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_160614.mwk\n",
      "N valid trials: 827\n",
      "... Getting session summary ...\n",
      "... Getting stimulus counts ...\n",
      "... Plotting stats by transform ...\n",
      "[('Blob_N2_y60', 0.5813953488372093), ('Blob_N2_y45', 0.5531914893617021), ('Blob_N1_y45', 0.9347826086956522), ('Blob_N1_y60', 0.8936170212765957), ('Blob_N2_y15', 0.6808510638297872), ('Blob_N1_y-30', 0.9069767441860465), ('Blob_N1_y-15', 0.9111111111111111), ('Blob_N1_y0', 0.9333333333333333), ('Blob_N2_y30', 0.5106382978723404), ('Blob_N1_y-45', 0.9130434782608695), ('Blob_N2_y-45', 0.717391304347826), ('Blob_N2_y0', 0.6444444444444445), ('Blob_N1_y30', 0.9333333333333333), ('Blob_N2_y-60', 0.851063829787234), ('Blob_N1_y15', 0.8541666666666666), ('Blob_N2_y-15', 0.7291666666666666), ('Blob_N1_y-60', 0.8695652173913043), ('Blob_N2_y-30', 0.8043478260869565)]\n",
      "{'session': '20150713', 'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150713.mwk'], 'animal': 'AG2'}\n",
      "***** Parsing trials *****\n",
      "N total response events:  1017\n",
      "N total outcome events:  1017\n",
      "Found and removed 74 orphan stimulus events in file /n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_160317.mwk\n",
      "N valid trials: 943\n",
      "... Getting session summary ...\n",
      "... Getting stimulus counts ...\n",
      "... Plotting stats by transform ...\n",
      "[('Blob_N2_y60', 0.75), ('Blob_N2_y45', 0.7407407407407407), ('Blob_N1_y45', 0.7307692307692307), ('Blob_N1_y60', 0.5283018867924528), ('Blob_N2_y15', 0.7169811320754716), ('Blob_N1_y-30', 0.8846153846153846), ('Blob_N1_y-15', 0.9433962264150944), ('Blob_N1_y0', 0.96), ('Blob_N2_y30', 0.7115384615384616), ('Blob_N1_y-45', 0.6923076923076923), ('Blob_N2_y-45', 0.6862745098039216), ('Blob_N2_y0', 0.7884615384615384), ('Blob_N1_y30', 0.9074074074074074), ('Blob_N2_y-60', 0.6730769230769231), ('Blob_N1_y15', 0.9803921568627451), ('Blob_N2_y-15', 0.7551020408163265), ('Blob_N1_y-60', 0.4909090909090909), ('Blob_N2_y-30', 0.7857142857142857)]\n",
      "{'session': '20160126', 'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_160126.mwk'], 'animal': 'AG2'}\n",
      "***** Parsing trials *****\n"
     ]
    }
   ],
   "source": [
    "# Process all new sessions:\n",
    "processed_sessions = process_sessions_mp(new_sessions, session_info,\n",
    "                                         output_figdir=output_figdir,\n",
    "                                         nprocesses=4,\n",
    "                                         ignore_flags=ignore_flags,\n",
    "                                         response_types=response_types,\n",
    "                                         outcome_types=outcome_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AG1] ~~~ processing complete! ~~~\n"
     ]
    }
   ],
   "source": [
    "# Update animal sessions dict:\n",
    "for datestr, S in processed_sessions.items():\n",
    "    animal.sessions.update({datestr: S})\n",
    "\n",
    "# Save to disk:\n",
    "try:\n",
    "    with open(animal_datafile, 'wb') as f:\n",
    "        pkl.dump(animal, f, protocol=pkl.HIGHEST_PROTOCOL)\n",
    "except PicklingError:\n",
    "    print(\"Unable to pkl: New sessions are not the same class as old sessions.\")\n",
    "    print(\"Reprocessing %i old sessions...\" % len(processed_sessions))\n",
    "    for datestr in old_sessions:\n",
    "        session_meta = session_info[datestr]\n",
    "        S = process_session(session_meta)\n",
    "        animal.sessions[datestr] = S\n",
    "        \n",
    "    with open(animal_datafile, 'wb') as f:\n",
    "        pkl.dump(animal, f, protocol=pkl.HIGHEST_PROTOCOL)\n",
    "\n",
    "print(\"[%s] ~~~ processing complete! ~~~\" % animal.animalid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'session': '20151119', 'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_151119.mwk'], 'animal': 'AG2'}\n",
      "***** Parsing trials *****\n",
      "... Getting session summary ...\n",
      "... Getting stimulus counts ...\n",
      "{'session': '20151118', 'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_151118.mwk'], 'animal': 'AG2'}\n",
      "***** Parsing trials *****\n",
      "... Getting session summary ...\n",
      "... Getting stimulus counts ...\n",
      "{'session': '20151120', 'datasource': ['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_151120.mwk'], 'animal': 'AG2'}\n",
      "***** Parsing trials *****\n",
      "N total response events:  0\n",
      "N total outcome events:  0\n",
      "Found and removed 0 orphan stimulus events in file /n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_151120.mwk\n",
      "N valid trials: 0\n",
      "... Getting session summary ...\n",
      "... Getting stimulus counts ...\n"
     ]
    }
   ],
   "source": [
    "# Reprocess buggy datafiles:\n",
    "\n",
    "# processed_sessions = {}\n",
    "# for datestr in new_sessions:\n",
    "#     session_meta = session_info[datestr]\n",
    "#     S = process_session(session_meta, \n",
    "#                         output_figdir=output_figdir,\n",
    "#                         ignore_flags=ignore_flags,\n",
    "#                         response_types=response_types, \n",
    "#                         outcome_types=outcome_types)\n",
    "#     processed_sessions[datestr] = S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save processed sessions to animal object in case MP errors out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 183 processed sessions in tmp dir.\n",
      "[AG1] ~~~ processed session update complete! ~~~\n"
     ]
    }
   ],
   "source": [
    "tmp_processed_sessions = glob.glob(os.path.join(output_figdir, 'tmp_files', 'proc_%s*.pkl' % animal.animalid))\n",
    "print(\"Found %i processed sessions in tmp dir.\" % len(tmp_processed_sessions))\n",
    "\n",
    "for tmpfile in tmp_processed_sessions:\n",
    "    with open(tmpfile, 'rb') as f:\n",
    "        tmpS = pkl.load(f)\n",
    "    datestr = os.path.splitext(os.path.split(tmpfile)[-1])[0].split('_')[2]\n",
    "    #print datestr\n",
    "    animal.sessions.update({datestr: tmpS})\n",
    "\n",
    "\n",
    "\n",
    "# Save to disk:\n",
    "try:\n",
    "    with open(animal_datafile, 'wb') as f:\n",
    "        pkl.dump(animal, f, protocol=pkl.HIGHEST_PROTOCOL)\n",
    "except PicklingError:\n",
    "    print(\"Unable to pkl: New sessions are not the same class as old sessions.\")\n",
    "    print(\"Reprocessing %i old sessions...\" % len(processed_sessions))\n",
    "    for datestr in old_sessions:\n",
    "        session_meta = session_info[datestr]\n",
    "        S = process_session(session_meta)\n",
    "        animal.sessions[datestr] = S\n",
    "        \n",
    "    with open(animal_datafile, 'wb') as f:\n",
    "        pkl.dump(animal, f, protocol=pkl.HIGHEST_PROTOCOL)\n",
    "\n",
    "print(\"[%s] ~~~ processed session update complete! ~~~\" % animal.animalid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking funky files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Event before 7216099 was missing required code, time, and/or value\n"
     ]
    }
   ],
   "source": [
    "fn = '/media/julianarhee/BK/mworks_data/AG/AG2_150803.mwk'\n",
    "df = pymworks.open(fn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response types: ['Announce_AcquirePort1', 'Announce_AcquirePort3', 'ignore']\n",
      "outcome_types: ['success', 'ignore', 'failure']\n"
     ]
    }
   ],
   "source": [
    "print \"response types:\", response_types\n",
    "print \"outcome_types:\", outcome_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Announce_AcquirePort1', 'Announce_AcquirePort3', 'ignore']\n",
      "['success', 'ignore', 'failure']\n",
      "N total response events:  0\n",
      "N total outcome events:  0\n",
      "Found and removed 0 orphan stimulus events in file /media/julianarhee/BK/mworks_data/AG/AG2_150803.mwk\n",
      "N valid trials: 0\n"
     ]
    }
   ],
   "source": [
    "trials, flags = parse_trials(df, response_types=response_types, ignore_flags=ignore_flags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.895642"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boundary = get_run_time(df)\n",
    "(boundary[1] - boundary[0]) /1E6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Event[code=5, name=#state_system_mode, time=422098815072, value=0],\n",
       " Event[code=5, name=#state_system_mode, time=422098998966, value=0],\n",
       " Event[code=5, name=#state_system_mode, time=422131902902, value=2],\n",
       " Event[code=5, name=#state_system_mode, time=422131902909, value=2],\n",
       " Event[code=5, name=#state_system_mode, time=422133798544, value=1],\n",
       " Event[code=5, name=#state_system_mode, time=422133799168, value=0],\n",
       " Event[code=5, name=#state_system_mode, time=422135401853, value=2],\n",
       " Event[code=5, name=#state_system_mode, time=422135401859, value=2],\n",
       " Event[code=5, name=#state_system_mode, time=428988902033, value=1],\n",
       " Event[code=5, name=#state_system_mode, time=428988902618, value=0]]"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.get_events('#state_system_mode')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing / debugging Session objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150314.mwk\n"
     ]
    }
   ],
   "source": [
    "curr_session = 20150314 #20160623 #session_list[pre_morphs] # 20150211\n",
    "\n",
    "datestr = session_list[session_list.index(curr_session)]\n",
    "dfn = [f for f in raw_fns if animalid in f and str(datestr)[2:] in f][0]\n",
    "print dfn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Announce_AcquirePort1', 'Announce_AcquirePort3', 'ignore']\n",
      "['success', 'ignore', 'failure']\n",
      "N total response events:  1051\n",
      "N total outcome events:  1051\n",
      "Found and removed 110 orphan stimulus events in file /n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_160623.mwk\n",
      "N valid trials: 941\n"
     ]
    }
   ],
   "source": [
    "# df = pymworks.open(dfn)\n",
    "# trials, flags = parse_trials(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Announce_AcquirePort1', 'Announce_AcquirePort3', 'ignore']\n",
      "['success', 'ignore', 'failure']\n",
      "N total response events:  335\n",
      "N total outcome events:  335\n",
      "Found and removed 57 orphan stimulus events in file /n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_150314.mwk\n",
      "N valid trials: 278\n"
     ]
    }
   ],
   "source": [
    "S = Session(dfn)\n",
    "S.parse_trials(response_types=['Announce_AcquirePort1', 'Announce_AcquirePort3', 'ignore'], \\\n",
    "                 outcome_types = ['success', 'ignore', 'failure'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "S.get_counts_by_stimulus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Blob_N2_CamRot_y0', 'Blob_N1_CamRot_y0']\n"
     ]
    }
   ],
   "source": [
    "# Check if there are morphs also:\n",
    "morph_list = [s for s in S.stats.keys() if 'morph' in s]\n",
    "if len(morph_list) > 0:\n",
    "    stimulus_list = [s for s in S.stats.keys() if s not in morph_list]\n",
    "else:\n",
    "    stimulus_list = S.stats.keys()\n",
    "print stimulus_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "values = [('%s_%s' % (stim.split('_')[1], stim.split('_')[3]), \\\n",
    "                       S.stats[stim]['nsuccess']/float(S.stats[stim]['ntrials'])) for stim in stimulus_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('N2_y0', 0.9496402877697842), ('N1_y0', 0.9136690647482014)]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['morph0', 'morph1', 'morph3', 'morph5', 'morph6', 'morph7', 'morph8', 'morph9', 'morph12', 'morph13', 'morph10', 'morph11', 'morph16', 'morph14', 'morph15', 'morph2', 'morph4']\n"
     ]
    }
   ],
   "source": [
    "#stimulus_list = S.stimuli\n",
    "stimulus_list = [s for s in S.stats.keys() if 'morph' in s]\n",
    "\n",
    "print stimulus_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = [('morph_%s' % (stim.split('morph')[1]), \\\n",
    "                       S.stats[stim]['nchoose1']/float(S.stats[stim]['ntrials'])) for stim in stimulus_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('morph_0', 0.0),\n",
       " ('morph_1', 0.0),\n",
       " ('morph_3', 0.0),\n",
       " ('morph_5', 0.0),\n",
       " ('morph_6', 0.0),\n",
       " ('morph_7', 0.0),\n",
       " ('morph_8', 0.14285714285714285),\n",
       " ('morph_9', 0.14285714285714285),\n",
       " ('morph_12', 0.5714285714285714),\n",
       " ('morph_13', 0.875),\n",
       " ('morph_10', 0.375),\n",
       " ('morph_11', 0.5),\n",
       " ('morph_16', 1.0),\n",
       " ('morph_14', 0.625),\n",
       " ('morph_15', 0.7142857142857143),\n",
       " ('morph_2', 0.0),\n",
       " ('morph_4', 0.14285714285714285)]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare session numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20150202 20150203 20150204 20150205 20150206 20150207 20150208 20150209\n",
      " 20150210 20150211]\n"
     ]
    }
   ],
   "source": [
    "dates = np.arange(all_sessions[0], all_sessions[-1])\n",
    "print dates[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_list = ['r', 'g', 'b']\n",
    "pl.figure(figsize=(20,5))\n",
    "for ai, animal in enumerate(sessions.keys()):\n",
    "    session_list = sessions[animalid]\n",
    "    pl.scatter([i for i in np.arange(len(dates))], [1+ai if dt in session_list else 0 for dt in dates], color=color_list[ai])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/n/coxfs01/behavior-data/threeport_morphs/AG/raw/AG2_161130.mwk']\n"
     ]
    }
   ],
   "source": [
    "datestr = session_list[-10]\n",
    "dfn = [f for f in raw_fns if animalid in f and str(datestr)[2:] in f] # saved datestr is YYMMDD.mwk\n",
    "print dfn\n",
    "dfn = dfn[0]\n",
    "df = pymworks.open(dfn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "codec = df.get_codec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "codec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.get_events('TooFast_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstarts = [t for t in df.get_events('Announce_TrialStart') if t.value==1]\n",
    "tends = [t for t in df.get_events('Announce_TrialEnd') if t.value==1]\n",
    "print len(tstarts)\n",
    "print len(tends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "446+447+37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
